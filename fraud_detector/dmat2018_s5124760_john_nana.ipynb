{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creditcard', 'creditcard.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Sampling imports\n",
    "from numpy import genfromtxt\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = [\"Normal\",\"Fraud\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "#reading dataset\n",
    "card_data = pd.read_csv(\"../input/creditcard.csv\")\n",
    "card_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm there are no null values\n",
    "card_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1bae0abd2b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAExCAYAAACqHw9wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOicbMzMr3f8BvxD863X1ofEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bae0a34cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# unbalanced dataset\n",
    "card_data['Class'].value_counts().plot.bar()\n",
    "plt.xticks(range(2), LABELS)\n",
    "plt.title(\"Frequency by observation number\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.359826</td>\n",
       "      <td>0.072213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.191854</td>\n",
       "      <td>-0.264279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.358352</td>\n",
       "      <td>1.341182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.966252</td>\n",
       "      <td>0.185364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.158231</td>\n",
       "      <td>-0.876616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  1.359826  0.072213\n",
       "1 -1.191854 -0.264279\n",
       "2  1.358352  1.341182\n",
       "3  0.966252  0.185364\n",
       "4  1.158231 -0.876616"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "#card_data_2d = pd.DataFrame(pca.fit_transform(card_data[:,1:30]))\n",
    "card_data_2d = pd.DataFrame(pca.fit_transform(card_data.drop(['Amount', 'Class','Time'], axis=1))) \n",
    "card_data_2d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 'Class'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_data_2d = pd.concat([card_data_2d, card_data['Class']], axis=1)\n",
    "card_data_2d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "card_data_2d.columns = ['x', 'y', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.359826</td>\n",
       "      <td>0.072213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.191854</td>\n",
       "      <td>-0.264279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.358352</td>\n",
       "      <td>1.341182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.966252</td>\n",
       "      <td>0.185364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.158231</td>\n",
       "      <td>-0.876616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y  class\n",
       "0  1.359826  0.072213      0\n",
       "1 -1.191854 -0.264279      0\n",
       "2  1.358352  1.341182      0\n",
       "3  0.966252  0.185364      0\n",
       "4  1.158231 -0.876616      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_data_2d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1bae0b4a240>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAFgCAYAAACloT70AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVwozMwskwuFmZllcqEwM7NM/w8nrOBKNDdI2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bae0b4a438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot(x=\"x\",y=\"y\", data=card_data_2d, fit_reg = False, hue=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10    ...          V19       V20       V21  \\\n",
       "0  0.098698  0.363787  0.090794    ...     0.403993  0.251412 -0.018307   \n",
       "1  0.085102 -0.255425 -0.166974    ...    -0.145783 -0.069083 -0.225775   \n",
       "2  0.247676 -1.514654  0.207643    ...    -2.261857  0.524980  0.247998   \n",
       "3  0.377436 -1.387024 -0.054952    ...    -1.232622 -0.208038 -0.108300   \n",
       "4 -0.270533  0.817739  0.753074    ...     0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724  \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_data.drop(['Amount', 'Class','Time'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada = ADASYN()\n",
    "X_resampled, y_resampled = ada.fit_sample(card_data.drop(['Amount', 'Class','Time'], axis=1),card_data['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_y_resampled =  pd.DataFrame(y_resampled)\n",
    "labeled_y_resampled.columns=['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568615, 29)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_data_oversampled = pd.concat([pd.DataFrame(X_resampled), labeled_y_resampled], axis=1)\n",
    "card_data_oversampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "          7         8         9  ...          19        20        21  \\\n",
       "0  0.098698  0.363787  0.090794  ...    0.251412 -0.018307  0.277838   \n",
       "1  0.085102 -0.255425 -0.166974  ...   -0.069083 -0.225775 -0.638672   \n",
       "2  0.247676 -1.514654  0.207643  ...    0.524980  0.247998  0.771679   \n",
       "3  0.377436 -1.387024 -0.054952  ...   -0.208038 -0.108300  0.005274   \n",
       "4 -0.270533  0.817739  0.753074  ...    0.408542 -0.009431  0.798278   \n",
       "\n",
       "         22        23        24        25        26        27  class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_data_oversampled.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1bae17d0c88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAExCAYAAACqHw9wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcHFW5//HPl7BvCYGAkIWwxIU1QgQEr4IoBBCCXFBQ\nIUo0XoV7Ufkhyw+JELmiCChXhcsSCMhiZI0YhIgERFkSFlnVjGyJCQkQlkAIGHjuH3VaKk1PdyWZ\nmgo93/frVa+uOnXq1FM9PfNMVZ0+pYjAzMysTCtUHYCZmbU/JxszMyudk42ZmZXOycbMzErnZGNm\nZqVzsjEzs9I52Zg1ICkkbV7yPgan/axY5n66mqTPS7q56jiWhaRdJc2sOo6exMnG/kXSk5Jek/RK\nbtqo6risOo0SYkRcFhF7VBmXvfs42Vi9fSNizdw0q77Cu+0/8Z5MGf+el8i/D8X4Q2gt5f67HSXp\naeD3qXwnSX+S9KKkP0vaNbfNJpJukzRf0mRJP5X0i7TuHZcw0lnVJ9L8CpKOk/R3Sc9LmiCpb10s\nIyU9Lek5Sf8/104vSSekbedLulfSQEk/k3RG3T5/LekbTQ59b0mPp32cnuJaRdI8SVvn2lk/nRH2\na/DerSDpRElPSZor6RJJveuqHS5plqTZko7ObbuDpGmSXpY0R9KZuXXN3vspkk6V9EdgAXCCpGl1\ncX1T0sQ0v4+k+9N+Zkj6bq7q7en1xXSm+2FJX5R0R66tnSVNlfRSet25Lpaxkv6Yfh43S1qv0Ztd\n+1xIOjq9V7MlfamurS/nluvjCElflzQ97WuspM0k3ZmObYKklev2eUL6+T4p6fO58lUk/Sh9xuZI\nOlfSanVxHivpGeCiRsdjdSLCkyciAuBJ4BMNygcDAVwCrAGsBvQHngf2Jvun5ZNpuV/a5k7gTGAV\n4KPAfOAXad2uwMzO9g18A7gLGJC2/1/girpYzk9xbAu8DnwgrT8GeAh4H6C0fl1gB2AWsEKqtx7Z\nH+INOnkvArgV6AsMAv4GfDmt+znwg1zdo4Bfd9LO4UAHsCmwJnANcGndsVyR3tetgWdz78OdwKFp\nfk1gpzTf6r2fAjwNbAmsCPRO7/+QXFxTgYNzP4+tU1vbAHOA/etiXDG37ReBO9J8X+AF4NC0r0PS\n8rq5WP4OvDf9vKYAp3XyXu0KLAJOAVZKx7cAWCfX1pcbxZH7mU0E1k7H/jpwS3rvewOPAiPr9lX7\njH4MeBV4X1r/49RWX2At4NfA9+u2/UHadrWqf3ffDVPlAXhafiayP/ivAC+m6bpUXvuDs2mu7rGk\nP5q5spuAkWR/nBcBa+TWXU7xZPMYsHtu3YbAP9Mfs1osA3Lr7+HtP5x/BUZ0cnyPAZ9M80cCk5q8\nFwEMzy1/Hbglze8IzODtxDUN+Ewn7dwCfD23/L4Gx/L+3PofAhem+duBk4H16trs9L1P81OAU+rW\n/wI4Kc0PIUs+q3cS84+Bs+p+9p0lm0OBe+q2vxP4Yi6WE+vex992st9dgdfq9jWXt5PsFFonm11y\ny/cCx+aWzwB+nNtX/Wd0AvAdsn9SXgU2y637MPBEbts3gFWr/p19N02+jGb19o+IPmnav27djNz8\nxsBB6TLOi5JeBD5Clhg2Al6IiFdz9Z9aghg2Bq7NtfsY8CawQa7OM7n5BWT/+QMMJPtPupHxwBfS\n/BeAS1vEkT/ep8iOi4i4m+yP0cckvR/YnOy/4EY2YvFjf4os0eSPpeF+gFFkZwR/SZenPpXKm733\njdqELNkfkuY/R/aPxAIASTtKulXSs5JeAv6D7MyviPrjqx1D/9xyZz+rRp6PiEVLUL/enNz8aw2W\n8201+oxuBPQDVgfuzb2/v03lNc9GxMIliKvHc7KxJZEfInwG2X/XfXLTGhFxGjAbWEfSGrn6g3Lz\nr5L9MgPZfRYW/0WeAexV1/aqEfGPAjHOADbrZN0vgBGStgU+AFzXoq2BdfHnO0vUEtehwFVN/vDM\nIksO+XYWsfgfwYb7iYjpEXEIsD7ZJZur0nva7L2vqR/O/WZgPUlDyZLO5bl1l5Mly4ER0Rs4l+y/\n+0bttDq+2jEU+VktqcU+N8B7lrG9Rp/RWcBzZIlpy9z72zsi8onKw+UvIScbW1q/APaVtGe6Kb9q\nunE6ICKeIru0dLKklSV9BNg3t+3fgFXTjemVgBPJrn3XnAucKmljAEn9JI0oGNcFwFhJQ5TZRtK6\nABExk+xexaXA1RHxWou2jpG0jqSBZPdlfplbdynwabKEc0mTNq4Avqmsw8SawH8Dv6z77/07klaX\ntCXwpdp+JH1BUr+IeIvssiZkZ3idvvedBZH2dxVwOtl9iMm51WsB8yJioaQdyM58ap4F3iK779HI\nJOC9kj4naUVJnwW2AG5o8p4srQeAA9J7tTnZmd+yqn1G/w34FPCr9H6fD5wlaX0ASf0l7dkF++ux\nnGxsqUTEDGAEcALZH6QZZDfna5+pz5Hd25gHjCH3BzkiXiK7dn8B2X/ArwL53mk/IftP+2ZJ88k6\nC+xYMLQzya693wy8DFxIdmO6ZjzZzfBWl9AArie77v8A8JvUVu0YZgL3kf2H+4cmbYxL+7odeAJY\nCPxnXZ3byDoR3AL8KCJqX5gcDjwi6RWy9+TgiFhY4L3vzOXAJ8j+oOaT3deBU9J7fRLZ+1c7zgXA\nqcAf0yWlnfINRsTzZH+kjybrpPBt4FMR8VyLWJbGWWT3SuaQ/RwvW8b2niHrzDArtfUfEfGXtO5Y\nsp/JXZJeBn5Hdr/NlpLSDS+zUqXutJtHxBda1S05jo+SnRkMTv/BLktb44BZEXFilwRn1sb8ZSTr\nMdIlu6OAC7og0QwGDgA+uOyRmbU/X0azHkHSB8jue2xI1rV3WdoaCzwMnB4RT3RBeGZtz5fRzMys\ndD6zMTOz0jnZmJlZ6dxBIFlvvfVi8ODBVYdhZvaucu+99z4XEe8YhLaek00yePBgpk2b1rqimZn9\ni6RCQ1H5MpqZmZXOycbMzErnZGNmZqVzsjEzs9I52ZiZWemcbMzMrHRONmZmVjonGzMzK52/1Pku\nM/i431QdQlt58rR9qg6hbfiz2bXa7bPpMxszMyudk42ZmZXOycbMzErnZGNmZqVzsjEzs9I52ZiZ\nWemcbMzMrHRONmZmVjonGzMzK52TjZmZlc7JxszMSudkY2ZmpXOyMTOz0jnZmJlZ6ZxszMysdE42\nZmZWOicbMzMrnZONmZmVzsnGzMxK52RjZmalc7IxM7PSlZZsJA2UdKukxyQ9IumoVP5dSf+Q9ECa\n9s5tc7ykDkl/lbRnrnx4KuuQdFyufBNJd0uaLumXklZO5auk5Y60fnBZx2lmZq2VeWazCDg6Ij4A\n7AQcIWmLtO6siBiapkkAad3BwJbAcODnknpJ6gX8DNgL2AI4JNfOD1JbQ4AXgFGpfBTwQkRsDpyV\n6pmZWUVKSzYRMTsi7kvz84HHgP5NNhkBXBkRr0fEE0AHsEOaOiLi8Yh4A7gSGCFJwMeBq9L244H9\nc22NT/NXAbun+mZmVoFuuWeTLmN9ELg7FR0p6UFJ4yStk8r6AzNym81MZZ2Vrwu8GBGL6soXayut\nfynVr49rtKRpkqY9++yzy3SMZmbWudKTjaQ1gauBb0TEy8A5wGbAUGA2cEataoPNYynKm7W1eEHE\neRExLCKG9evXr+lxmJnZ0is12UhaiSzRXBYR1wBExJyIeDMi3gLOJ7tMBtmZycDc5gOAWU3KnwP6\nSFqxrnyxttL63sC8rj06MzMrqszeaAIuBB6LiDNz5Rvmqn0aeDjNTwQOTj3JNgGGAPcAU4EhqefZ\nymSdCCZGRAC3Agem7UcC1+faGpnmDwR+n+qbmVkFVmxdZantAhwKPCTpgVR2AllvsqFkl7WeBL4K\nEBGPSJoAPErWk+2IiHgTQNKRwE1AL2BcRDyS2jsWuFLS94D7yZIb6fVSSR1kZzQHl3icZmbWQmnJ\nJiLuoPG9k0lNtjkVOLVB+aRG20XE47x9GS5fvhA4aEniNTOz8ngEATMzK52TjZmZlc7JxszMSudk\nY2ZmpXOyMTOz0jnZmJlZ6ZxszMysdE42ZmZWuiVKNpLWkbRNWcGYmVl7aplsJE2RtLakvsCfgYsk\nndlqOzMzs5oiZza906MBDgAuiojtgU+UG5aZmbWTIslmxTRS82eAG0qOx8zM2lCRZHMK2YjLHREx\nVdKmwPRywzIzs3bSctTniPgV8Kvc8uPAv5cZlJmZtZeWyUZSP+ArwOB8/Yg4vLywzMysnRR5ns31\nwB+A3wFvlhuOmZm1oyLJZvWIOLb0SMzMrG0V6SBwg6S9S4/EzMzaVpFkcxRZwlkoaX6aXi47MDMz\nax9FeqOt1R2BmJlZ+ypyzwZJ+wEfTYtTIsJf7jQzs8KKjI12GtmltEfTdFQqMzMzK6TImc3ewNCI\neAtA0njgfuC4MgMzM7P2UfQRA31y873LCMTMzNpXkTOb7wP3S7oVENm9m+NLjcrMzNpKkd5oV0ia\nAnyILNkcGxHPlB2YmZm1j04vo0l6f3rdDtgQmAnMADZKZWZmZoU0u2fzrfR6RoPpR60aljRQ0q2S\nHpP0iKSjUnlfSZMlTU+v66RySTpbUoekB/MJTdLIVH+6pJG58u0lPZS2OVuSmu3DzMyq0WmyiYjR\naXaviNgtP5H1UGtlEXB0RHwA2Ak4QtIWZL3YbomIIcAtvN2rbS9gSJpGA+dAljiAMcCOwA7AmFzy\nOCfVrW03PJV3tg8zM6tAkd5ofypYtpiImB0R96X5+cBjQH9gBDA+VRsP7J/mRwCXROYuoE96Quie\nwOSImBcRLwCTgeFp3doRcWdEBHBJXVuN9mFmZhXotIOApPeQJYfVJH2QrHMAwNrA6kuyE0mDgQ8C\ndwMbRMRsyBKSpPVTtf5k94RqZqayZuUzG5TTZB9mZlaBZr3R9gS+CAwAzsyVzwdOKLoDSWsCVwPf\niIiX022VhlUblMVSlBcmaTTZZTgGDRq0JJuamdkS6DTZRMR4YLykf4+Iq5emcUkrkSWayyLimlQ8\nR9KG6YxjQ2BuKp8JDMxtPgCYlcp3rSufksoHNKjfbB/1x3gecB7AsGHDlihRmZlZcS3v2UTE1ZL2\nkfRtSSfVplbbpZ5hFwKPRUT+zGgiUOtRNpLsSaC18sNSr7SdgJfSpbCbgD0krZM6BuwB3JTWzZe0\nU9rXYXVtNdqHmZlVoOWXOiWdS3aPZjfgAuBA4J4Cbe8CHAo8JOmBVHYCcBowQdIo4GngoLRuElkv\ntw5gAfAlgIiYJ2ksMDXVOyUi5qX5rwEXA6sBN6aJJvswM7MKFBmuZueI2EbSgxFxsqQzgGtabRQR\nd9D4vgrA7g3qB3BEJ22NA8Y1KJ8GbNWg/PlG+zAzs2oU6fr8WnpdIGkj4J/AJuWFZGZm7abImc0N\nkvoApwP3kfX4Or/UqMzMrK0UGYhzbJq9WtINwKoR8VK5YZmZWTsp8qTOP0s6QdJmEfG6E42ZmS2p\nIvds9iMb52yCpKmS/p8kfwPSzMwKK/I9m6ci4ocRsT3wOWAb4InSIzMzs7ZRpINAbWyzzwCfBd4E\nvl1eSGZm1m6KfKnzbmAlYAJwUEQ8XnpUZmbWVpomG0krANdGxGndFI+ZmbWhpvdsIuItij0ozczM\nrFNFeqNNTj3QBqbHLfdNT880MzMrpEgHgcPTa37csgA27fpwzMysHRUZQcDjoJmZ2TIpMoLA6pJO\nlHReWh4i6VPlh2ZmZu2iyD2bi4A3gJ3T8kzge6VFZGZmbadIstksIn5I9mgBIuI1On9OjZmZ2TsU\nSTZvSFqNrFMAkjYDXi81KjMzaytFeqONAX4LDJR0Gdnjnr9YZlBmZtZeivRGmyzpPmAnsstnR0XE\nc6VHZmZmbaNIb7RdgIUR8RugD3CCpI1Lj8zMzNpGkXs25wALJG0LHAM8BVxSalRmZtZWiiSbRRER\nwAjg7Ij4CbBWuWGZmVk7KdJBYL6k44FDgX+T1IvskQNmZmaFFDmz+SxZV+fDI+IZoD9weqlRmZlZ\nWynyWOhngMuBdSTtC7wREb5nY2ZmhRXpjfZl4B7gAOBA4C5JhzffyszM7G1F7tkcA3wwIp4HkLQu\n8CdgXJmBmZlZ+yhyz2YmMD+3PB+Y0WojSeMkzZX0cK7su5L+IemBNO2dW3e8pA5Jf5W0Z658eCrr\nkHRcrnwTSXdLmi7pl5JWTuWrpOWOtH5wgWM0M7MSdZpsJH1L0reAfwB3p0QxBrgL6CjQ9sXA8Abl\nZ0XE0DRNSvvaAjgY2DJt83NJvVLPt58BewFbAIekugA/SG0NAV4ARqXyUcALEbE5cFaqZ2ZmFWp2\nZrNWmv4OXEcaiBO4HpjdquGIuB2YVzCOEcCVEfF6RDxBlsx2SFNHRDweEW8AVwIjJAn4OHBV2n48\nsH+urfFp/ipg91TfzMwq0uk9m4g4uTYvac2sKF7tgn0eKekwYBpwdES8QNad+q5cnZmpDBa/ZDcT\n2BFYF3gxIhY1qN+/tk1ELJL0Uqrv8dzMzCrS9J6NpK9JeppsiJqnJT0l6evLsL9zgM2AoWRnR2fU\ndtWgbixFebO23kHSaEnTJE179tlnm8VtZmbLoNk9mxOBfYFdI2LdiFgX2A3YK61bYhExJyLejIi3\ngPPJLpNBdmYyMFd1ADCrSflzQB9JK9aVL9ZWWt+bTi7nRcR5ETEsIob169dvaQ7JzMwKaHZmcyhw\nQEQ8XitI858BDluanUnaMLf4aaDWU20icHDqSbYJMITsuz1TgSGp59nKZJ0IJqax2m4l+94PwEiy\ne0m1tkam+QOB36f6ZmZWkabfs4mIhQ3KXpP0VquGJV0B7AqsJ2km2UPYdpU0lOyy1pPAV1Obj0ia\nADwKLAKOiIg3UztHAjcBvYBxEfFI2sWxwJWSvgfcD1yYyi8ELpXUQXZGc3CrWM3MrFzNks1MSbtH\nxC35Qkkfp1hvtEMaFF/YoKxW/1Tg1Ablk4BJDcof5+3LcPnyhcBBreIzM7Pu0yzZ/BdwvaQ7gHvJ\nzkY+RPZY6BHdEJuZmbWJTu/ZpMtVWwG3A4OBTdP8VrlLWWZmZi0VuWfjMdDMzGyZFBkbzczMbJk4\n2ZiZWemafanzlvTqgSzNzGyZNLtns6GkjwH7SbqSumFgIuK+UiMzM7O20SzZnAQcRzYUzJl164Js\n1GUzM7OWmo36fBVwlaTvRMTYbozJzMzaTMvHQkfEWEn7AR9NRVMi4oZywzIzs3bSsjeapO8DR5GN\nW/YocFQqMzMzK6TlmQ2wDzA0PRYASePJBr48vszAzMysfRT9nk2f3HzvMgIxM7P2VeTM5vvA/ZJu\nJev+/FF8VmNmZkugSAeBKyRNIRvxWcCxEfFM2YGZmVn7KHJmQ0TMJnsCppmZ2RLz2GhmZlY6Jxsz\nMytd02QjaQVJD3dXMGZm1p6aJpv03Zo/SxrUTfGYmVkbKtJBYEPgEUn3AK/WCiNiv9KiMjOztlIk\n2ZxcehRmZtbWinzP5jZJGwNDIuJ3klYHepUfmpmZtYsiA3F+BbgK+N9U1B+4rsygzMysvRTp+nwE\nsAvwMkBETAfWLzMoMzNrL0WSzesR8UZtQdKKZE/qNDMzK6RIsrlN0gnAapI+CfwK+HW5YZmZWTsp\nkmyOA54FHgK+CkwCTiwzKDMzay8tk036Yud4YCxZN+jxEdHyMpqkcZLm5kcgkNRX0mRJ09PrOqlc\nks6W1CHpQUnb5bYZmepPlzQyV769pIfSNmdLUrN9mJlZdYr0RtsH+DtwNvBToEPSXgXavhgYXld2\nHHBLRAwBbknLAHsBQ9I0Gjgn7bsvMAbYEdgBGJNLHuekurXthrfYh5mZVaTIZbQzgN0iYteI+Biw\nG3BWq40i4nZgXl3xCLKzJNLr/rnySyJzF9BH0obAnsDkiJgXES8Ak4Hhad3aEXFnOsu6pK6tRvsw\nM7OKFEk2cyOiI7f8ODB3Kfe3QXo2Tu0ZObUu1P2BGbl6M1NZs/KZDcqb7cPMzCrS6QgCkg5Is49I\nmgRMIOvyfBAwtYvjUIOyWIryJdupNJrsUhyDBnmsUTOzsjQ7s9k3TasCc4CPAbuS9Uxb2pvuc9Il\nMNJr7QxpJjAwV28AMKtF+YAG5c328Q4RcV5EDIuIYf369VvKQzIzs1Y6PbOJiC+VsL+JwEjgtPR6\nfa78SElXknUGeCkiZku6CfjvXKeAPYDjI2KepPmSdgLuBg4D/qfFPszMrCItB+KUtAnwn8DgfP1W\njxiQdAXZmdB6kmaS9So7DZggaRTwNNklOci+u7M30AEsAL6U9jFP0ljevmx3SkTUOh18jazH22rA\njWmiyT7MzKwiRR4xcB1wIdmoAW8VbTgiDulk1e4N6gbZGGyN2hkHjGtQPg3YqkH58432YWZm1SmS\nbBZGxNmlR2JmZm2rSLL5iaQxwM3A67XCiLivtKjMzKytFEk2WwOHAh/n7ctokZbNzMxaKpJsPg1s\nmn/MgJmZ2ZIoMoLAn4E+ZQdiZmbtq8iZzQbAXyRNZfF7Nk27PpuZmdUUSTZjSo/CzMzaWstkExG3\ndUcgZmbWvoqMIDCftwe5XBlYCXg1ItYuMzAzM2sfRc5s1sovS9qf7EFmZmZmhRTpjbaYiLgOf8fG\nzMyWQJHLaAfkFlcAhrEUz44xM7Oeq0hvtH1z84uAJ8kevWxmZlZIkXs2ZTzXxszMepBmj4U+qcl2\nERFjS4jHzMzaULMzm1cblK0BjALWBZxszMyskGaPhT6jNi9pLeAosidoXgmc0dl2ZmZm9Zres5HU\nF/gW8HlgPLBdRLzQHYGZmVn7aHbP5nTgAOA8YOuIeKXbojIzs7bS7EudRwMbAScCsyS9nKb5kl7u\nnvDMzKwdNLtns8SjC5iZmTXihGJmZqVzsjEzs9I52ZiZWemcbMzMrHRONmZmVjonGzMzK10lyUbS\nk5IekvSApGmprK+kyZKmp9d1UrkknS2pQ9KDkrbLtTMy1Z8uaWSufPvUfkfaVt1/lGZmVlPlmc1u\nETE0Ioal5eOAWyJiCHBLWgbYCxiSptHAOfCvoXTGADuSPaZ6TC1BpTqjc9sNL/9wzMysM8vTZbQR\nZOOvkV73z5VfEpm7gD6SNgT2BCZHxLw0XttkYHhat3ZE3BkRAVySa8vMzCpQVbIJ4GZJ90oanco2\niIjZAOl1/VTeH5iR23ZmKmtWPrNBuZmZVaTIY6HLsEtEzJK0PjBZ0l+a1G10vyWWovydDWeJbjTA\noEGDmkdsZmZLrZIzm4iYlV7nAteS3XOZky6BkV7npuozgYG5zQcAs1qUD2hQ3iiO8yJiWEQM69ev\n37IelpmZdaLbk42kNdLD2JC0BrAH8DAwEaj1KBsJXJ/mJwKHpV5pOwEvpctsNwF7SFondQzYA7gp\nrZsvaafUC+2wXFtmZlaBKi6jbQBcm3ojrwhcHhG/lTQVmCBpFPA0cFCqPwnYG+gAFpA9LZSImCdp\nLDA11TslIual+a8BFwOrATemyczMKtLtySYiHge2bVD+PLB7g/IAjuikrXHAuAbl04CtljlYMzPr\nEstT12czM2tTTjZmZlY6JxszMyudk42ZmZXOycbMzErnZGNmZqVzsjEzs9I52ZiZWemcbMzMrHRO\nNmZmVjonGzMzK52TjZmZlc7JxszMSudkY2ZmpXOyMTOz0jnZmJlZ6ZxszMysdE42ZmZWOicbMzMr\nnZONmZmVzsnGzMxK52RjZmalc7IxM7PSOdmYmVnpnGzMzKx0TjZmZlY6JxszMyudk42ZmZWubZON\npOGS/iqpQ9JxVcdjZtaTtWWykdQL+BmwF7AFcIikLaqNysys52rLZAPsAHRExOMR8QZwJTCi4pjM\nzHqsdk02/YEZueWZqczMzCqwYtUBlEQNyuIdlaTRwOi0+Iqkv5YaVc+yHvBc1UG0oh9UHYFVwJ/N\nrrVxkUrtmmxmAgNzywOAWfWVIuI84LzuCqonkTQtIoZVHYdZPX82q9Gul9GmAkMkbSJpZeBgYGLF\nMZmZ9VhteWYTEYskHQncBPQCxkXEIxWHZWbWY7VlsgGIiEnApKrj6MF8edKWV/5sVkAR77hvbmZm\n1qXa9Z6NmZktR5xszMysdE42ZmZWurbtIGDdR9IBzdZHxDXdFYtZnqSHaPCF7pqI2KYbw+nRnGys\nK+zbZF0ATjZWlU+l1yPS66Xp9fPAgu4Pp+dybzQza3uS/hgRu7Qqs/L4zMa6lKR9gC2BVWtlEXFK\ndRGZAbCGpI9ExB0AknYG1qg4ph7Fyca6jKRzgdWB3YALgAOBeyoNyiwzChgnqXdafhE4vMJ4ehxf\nRrMuI+nBiNgm97omcE1E7FF1bGYAktYm+7v3UtWx9DQ+s7Gu9Fp6XSBpI+B5YJMK4zEDQNJJdcuA\nL/F2Jycb60o3SOoDnA7cR9YT7YJqQzID4NXc/KpkvdQeqyiWHsmX0awUklYBVvXlClsepc/nxIjY\ns+pYegqf2ViXkdQL2AcYTPpsSSIizqwyLrMGVgc2rTqInsTJxrrSr4GFwEPAWxXHYvYvdSMJ9AL6\nAb5f0418Gc26TK0XWtVxmNWTtHFucREwJyIWVRVPT+SBOK0r3SjJ3ZxtuRMRT0XEU2Q9JnsBG0ka\nVHFYPYqTjXWlu4BrJb0m6WVJ8yW9XHVQZpL2kzQdeAK4DXgSuLHSoHoYJxvrSmcAHwZWj4i1I2Kt\niFi76qDMgLHATsDfImITYHfgj9WG1LM42VhXmg48HL4RaMuff0bE88AKklaIiFuBoVUH1ZO4N5p1\npdnAFEk3Aq/XCt312ZYDL6bhk24HLpM0l6yjgHUT90azLiNpTKPyiDi5u2Mxy5O0BlnngBXInmXT\nG7gsne1YN/CZjXWJ9IXONSPimKpjMctLn83rI+ITZN//Gl9xSD2S79lYl4iIN4Htqo7DrF76bC7I\nPV7AKuAzG+tKD0iaCPyK3MCHEeHHQlvVFgIPSZrM4p/N/6oupJ7Fyca6Ul+yxwp8PFcWgJONVe03\nabKKuIOAmbUtSYMi4umq4zDfs7EuJGmApGslzZU0R9LVkgZUHZf1aNfVZiRdXWUgPZ2TjXWli4CJ\nwEZAf7LHfJJrAAACnElEQVRRoC+qNCLr6ZSb9yMFKuRkY12pX0RcFBGL0nQx2VDuZlWJTuatm7mD\ngHWl5yR9AbgiLR9C1mHArCrbpsFgBayWGxhWQHjsvu7jDgLWZdKQ7T8lG4wzgD8BR6Wh3c2sB3Oy\nMTOz0vkymi0zSSc1WR0RMbbbgjGz5ZLPbGyZSTq6QfEawChg3YhYs5tDMrPljJONdSlJawFHkSWa\nCcAZETG32qjMrGq+jGZdQlJf4Ftkw7ePB7aLiBeqjcrMlhdONrbMJJ0OHACcB2wdEa9UHJKZLWd8\nGc2WmaS3yJ7MuYjFvzjn7zKYGeBkY2Zm3cDD1ZiZWemcbMzMrHRONmYVkPQeSVdK+rukRyVNkvRe\nSQ9XHZtZGdwbzaybSRJwLTA+Ig5OZUOBDSoNzKxEPrMx6367Af+MiHNrBRHxADCjtixpsKQ/SLov\nTTun8g0l3S7pAUkPS/o3Sb0kXZyWH5L0ze4/JLPmfGZj1v22Au5tUWcu8MmIWChpCNljG4YBnwNu\niohTJfUCVgeGAv0jYisASX3KC91s6TjZmC2fVgJ+mi6vvQm8N5VPBcZJWgm4LiIekPQ4sKmk/wF+\nA9xcScRmTfgymln3ewTYvkWdbwJzgG3JzmhWBoiI24GPAv8ALpV0WBoWaFtgCnAEcEE5YZstPScb\ns+73e2AVSV+pFUj6ELBxrk5vYHZEvAUcCvRK9TYG5kbE+cCFwHaS1gNWiIirge8A23XPYZgV58to\nZt0sIkLSp4EfSzoOWAg8CXwjV+3nwNWSDgJuBV5N5bsCx0j6J/AKcBjQH7hIUu2fx+NLPwizJeTh\naszMrHS+jGZmZqVzsjEzs9I52ZiZWemcbMzMrHRONmZmVjonGzMzK52TjZmZlc7JxszMSvd/NqP8\nzVY/LPcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bae1829780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## visual representation of the balanced dataset\n",
    "card_data_oversampled['class'].value_counts().plot.bar()\n",
    "plt.xticks(range(2), LABELS)\n",
    "plt.title(\"Frequency by observation number\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## to split data for training \n",
    "X = card_data_oversampled.iloc[:,0:28 ].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use one-hot encoding for classs labels\n",
    "y = card_data_oversampled['class']\n",
    "Y = keras.utils.to_categorical(y,num_classes=None)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis: A decrese in the number of neurons in the hidden layer will  affect the accuracy of prediction adversly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cross Validation using K-Fold method (k =10)\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conrtrol Arm with the number of input parameters as the number of neurons in the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline_history =None\n",
    "results_control_evaluation_accuracy =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 25s 49us/step - loss: 0.0569 - acc: 0.9877\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0514 - acc: 0.9925\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0361 - acc: 0.9944\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0351 - acc: 0.9952\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0308 - acc: 0.9958\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0352 - acc: 0.9955\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0294 - acc: 0.9963\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0242 - acc: 0.9968\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0262 - acc: 0.9968\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 26s 50us/step - loss: 0.0247 - acc: 0.9970\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0222 - acc: 0.9974 0s - loss: 0.0222 - a\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0219 - acc: 0.9975\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0185 - acc: 0.9978\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0313 - acc: 0.9971 0s - loss: 0.0314\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 24s 47us/step - loss: 0.0199 - acc: 0.9979\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 25s 49us/step - loss: 0.0195 - acc: 0.9978\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 24s 47us/step - loss: 0.0247 - acc: 0.9976\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 25s 48us/step - loss: 0.0211 - acc: 0.9979\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0259 - acc: 0.9976 1s - loss: 0\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 24s 46us/step - loss: 0.0269 - acc: 0.9976\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 24s 48us/step - loss: 0.0232 - acc: 0.9978\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 24s 47us/step - loss: 0.0172 - acc: 0.9982\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 24s 47us/step - loss: 0.0215 - acc: 0.9980\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 24s 48us/step - loss: 0.0263 - acc: 0.9977\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0154 - acc: 0.9984\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0217 - acc: 0.9981\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0207 - acc: 0.9981\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 24s 47us/step - loss: 0.0151 - acc: 0.9985\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0148 - acc: 0.9985\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0159 - acc: 0.9985\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0144 - acc: 0.9986\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0184 - acc: 0.9983\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0210 - acc: 0.9981\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0178 - acc: 0.9983\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0153 - acc: 0.9986\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0219 - acc: 0.9981\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0158 - acc: 0.9985\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0174 - acc: 0.9985\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0174 - acc: 0.9985 2s - loss: 0.0167  - ETA: \n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0193 - acc: 0.9983\n",
      "56862/56862 [==============================] - 1s 15us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 23s 46us/step - loss: 0.0604 - acc: 0.9883\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 23s 46us/step - loss: 0.0403 - acc: 0.9936\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0364 - acc: 0.9948\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0336 - acc: 0.9956\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0304 - acc: 0.9960\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 24s 46us/step - loss: 0.0264 - acc: 0.9967 1s - l\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0250 - acc: 0.9967\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 23s 46us/step - loss: 0.0319 - acc: 0.9966\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0234 - acc: 0.9973\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0212 - acc: 0.9974\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0216 - acc: 0.9974\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0210 - acc: 0.9975\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0204 - acc: 0.9977\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0211 - acc: 0.9977\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0169 - acc: 0.9980\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 24s 47us/step - loss: 0.0223 - acc: 0.9976\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0180 - acc: 0.9979 0s - loss: 0\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 23s 46us/step - loss: 0.0205 - acc: 0.9978 4s - loss: 0.02\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 25s 48us/step - loss: 0.0157 - acc: 0.9982\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0262 - acc: 0.9975\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0145 - acc: 0.9983\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0311 - acc: 0.9973\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0259 - acc: 0.9976\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 25s 48us/step - loss: 0.0245 - acc: 0.9977\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 24s 47us/step - loss: 0.0205 - acc: 0.9981\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0237 - acc: 0.9978\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0177 - acc: 0.9982\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 20s 38us/step - loss: 0.0207 - acc: 0.9980 1s \n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 19s 38us/step - loss: 0.0200 - acc: 0.9981\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0202 - acc: 0.9981\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 19s 38us/step - loss: 0.0199 - acc: 0.9981\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 20s 38us/step - loss: 0.0176 - acc: 0.9982\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0157 - acc: 0.9984\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 20s 38us/step - loss: 0.0151 - acc: 0.9984\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 20s 38us/step - loss: 0.0147 - acc: 0.9985\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0196 - acc: 0.9982\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 20s 38us/step - loss: 0.0162 - acc: 0.9984\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 20s 38us/step - loss: 0.0171 - acc: 0.9984\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0155 - acc: 0.9985\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 20s 38us/step - loss: 0.0163 - acc: 0.9984\n",
      "56862/56862 [==============================] - 1s 14us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0615 - acc: 0.9876 0s - loss: 0.0616 - acc: 0.9\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0418 - acc: 0.9931\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0429 - acc: 0.9939\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0424 - acc: 0.9944\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0431 - acc: 0.9947\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0316 - acc: 0.9958\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0276 - acc: 0.9961\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0299 - acc: 0.9960\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0241 - acc: 0.9967\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0237 - acc: 0.9968\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0231 - acc: 0.9971\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0311 - acc: 0.9965\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0203 - acc: 0.9974\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0174 - acc: 0.9977\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0198 - acc: 0.9976\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0186 - acc: 0.9977\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0245 - acc: 0.9974 0s - loss: 0.0246 - acc: \n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0216 - acc: 0.9974\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0222 - acc: 0.9976 0s - loss: 0.0222 - ac\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0230 - acc: 0.9976 0s - loss: 0.0230 - acc: 0.9\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0176 - acc: 0.9981\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0192 - acc: 0.9980\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0186 - acc: 0.9981\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0200 - acc: 0.9979\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0221 - acc: 0.9979\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0174 - acc: 0.9982\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0183 - acc: 0.9982\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0152 - acc: 0.9985\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0151 - acc: 0.9985\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0171 - acc: 0.9983\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0188 - acc: 0.9982 0s - loss: 0.0189 -\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0260 - acc: 0.9978\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0234 - acc: 0.9979\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0206 - acc: 0.9982\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0219 - acc: 0.9981\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0226 - acc: 0.9980\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0200 - acc: 0.9982\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0287 - acc: 0.9977\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0234 - acc: 0.9980\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0201 - acc: 0.9982\n",
      "56862/56862 [==============================] - 1s 16us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0621 - acc: 0.9879\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0566 - acc: 0.9923\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0381 - acc: 0.9945\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0505 - acc: 0.9940\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0377 - acc: 0.9952 2s - loss: 0.0385 \n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0385 - acc: 0.9954\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0344 - acc: 0.9958\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0341 - acc: 0.9960\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0255 - acc: 0.9967\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 23s 46us/step - loss: 0.0288 - acc: 0.9966 0s - loss: 0.0284\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0249 - acc: 0.9970\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0292 - acc: 0.9967\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0221 - acc: 0.9973\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0207 - acc: 0.9974\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0232 - acc: 0.9973 0s - loss: 0.0232 - acc:\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0210 - acc: 0.9976\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0235 - acc: 0.9974\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0258 - acc: 0.9973\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0215 - acc: 0.9976 0s - loss: 0.0216 - acc: 0.99\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0246 - acc: 0.9973\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0237 - acc: 0.9974\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0200 - acc: 0.9977\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0213 - acc: 0.9976\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 27s 52us/step - loss: 0.0213 - acc: 0.9976\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0218 - acc: 0.9976\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0301 - acc: 0.9970\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0198 - acc: 0.9978\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0378 - acc: 0.9966\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0288 - acc: 0.9972\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0286 - acc: 0.9973\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0302 - acc: 0.9971\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0226 - acc: 0.9977\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0231 - acc: 0.9978\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0305 - acc: 0.9969\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0214 - acc: 0.9977\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0256 - acc: 0.9977\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0259 - acc: 0.9976\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0285 - acc: 0.9976\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0253 - acc: 0.9979\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0280 - acc: 0.9977\n",
      "56862/56862 [==============================] - 1s 18us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0630 - acc: 0.9878\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0400 - acc: 0.9937\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0356 - acc: 0.9949\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0304 - acc: 0.9957\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0272 - acc: 0.9963\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0251 - acc: 0.9966\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0207 - acc: 0.9972\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0205 - acc: 0.9974\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0269 - acc: 0.9970\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0209 - acc: 0.9976\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0219 - acc: 0.9975\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0209 - acc: 0.9977\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0263 - acc: 0.9974\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0306 - acc: 0.9971\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0215 - acc: 0.9976\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0179 - acc: 0.9979\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0223 - acc: 0.9977 2s - loss: 0.0230 - a - ET\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0231 - acc: 0.9976\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0212 - acc: 0.9978\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0177 - acc: 0.9981\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0173 - acc: 0.9981\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0158 - acc: 0.9983\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0178 - acc: 0.9982\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0165 - acc: 0.9984\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0175 - acc: 0.9983\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0159 - acc: 0.9985\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0187 - acc: 0.9982\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0188 - acc: 0.9983\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0157 - acc: 0.9985\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0158 - acc: 0.9986 0s - loss: 0.0158 \n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0199 - acc: 0.9983\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0145 - acc: 0.9986\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0161 - acc: 0.9985 0s - loss: 0.0162 - acc: 0.9\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0229 - acc: 0.9980\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0180 - acc: 0.9985\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0204 - acc: 0.9982\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0185 - acc: 0.9984\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0159 - acc: 0.9985\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0213 - acc: 0.9982\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0163 - acc: 0.9985\n",
      "56862/56862 [==============================] - 1s 18us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0676 - acc: 0.9877\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0415 - acc: 0.9937\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 23s 44us/step - loss: 0.0364 - acc: 0.9947\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0340 - acc: 0.9953\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0327 - acc: 0.9959\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0301 - acc: 0.9962\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0266 - acc: 0.9965 0s - loss: 0.0267 -\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0271 - acc: 0.9966\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0261 - acc: 0.9969\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0255 - acc: 0.9968\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0240 - acc: 0.9972\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0205 - acc: 0.9974\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0237 - acc: 0.9973\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0262 - acc: 0.9973\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0246 - acc: 0.9972\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0240 - acc: 0.9974\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0189 - acc: 0.9977\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0270 - acc: 0.9972\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0189 - acc: 0.9978\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0192 - acc: 0.9979\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0216 - acc: 0.9978\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0261 - acc: 0.9975\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0221 - acc: 0.9978\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0223 - acc: 0.9979\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0155 - acc: 0.9983\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0203 - acc: 0.9980\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 22s 43us/step - loss: 0.0193 - acc: 0.9981\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0160 - acc: 0.9984\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0175 - acc: 0.9982\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0199 - acc: 0.9981 0s - loss: \n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0210 - acc: 0.9981\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0164 - acc: 0.9984\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0209 - acc: 0.9982\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0319 - acc: 0.9975\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 22s 43us/step - loss: 0.0212 - acc: 0.9982\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 23s 44us/step - loss: 0.0193 - acc: 0.9983\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 22s 43us/step - loss: 0.0266 - acc: 0.9979\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0214 - acc: 0.9982 0s - loss: 0.020\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0223 - acc: 0.9982\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0174 - acc: 0.9985\n",
      "56861/56861 [==============================] - 1s 18us/step \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 24s 46us/step - loss: 0.0623 - acc: 0.9881\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 22s 44us/step - loss: 0.0587 - acc: 0.9924\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 22s 44us/step - loss: 0.0399 - acc: 0.9943\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 22s 43us/step - loss: 0.0354 - acc: 0.9952\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 22s 43us/step - loss: 0.0334 - acc: 0.9956\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 23s 44us/step - loss: 0.0457 - acc: 0.9951\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 22s 43us/step - loss: 0.0485 - acc: 0.9949\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 23s 45us/step - loss: 0.0323 - acc: 0.9962\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 22s 44us/step - loss: 0.0306 - acc: 0.9965\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 22s 44us/step - loss: 0.0290 - acc: 0.9967\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 23s 44us/step - loss: 0.0473 - acc: 0.9956\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 27s 52us/step - loss: 0.0310 - acc: 0.9965\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 25s 48us/step - loss: 0.0295 - acc: 0.9968\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 25s 50us/step - loss: 0.0257 - acc: 0.9971\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 28s 54us/step - loss: 0.0292 - acc: 0.9970\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 27s 53us/step - loss: 0.0265 - acc: 0.9972\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 27s 53us/step - loss: 0.0287 - acc: 0.9970 0s - loss: 0.0280 \n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 27s 54us/step - loss: 0.0252 - acc: 0.9972\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 27s 53us/step - loss: 0.0236 - acc: 0.9974\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 28s 54us/step - loss: 0.0230 - acc: 0.9975\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 28s 55us/step - loss: 0.0257 - acc: 0.9974\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 28s 55us/step - loss: 0.0233 - acc: 0.9975\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 27s 53us/step - loss: 0.0214 - acc: 0.9976\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 27s 54us/step - loss: 0.0194 - acc: 0.9979\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 24s 46us/step - loss: 0.0220 - acc: 0.9977\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 23s 46us/step - loss: 0.0236 - acc: 0.9975\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 24s 48us/step - loss: 0.0208 - acc: 0.9979\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 23s 45us/step - loss: 0.0270 - acc: 0.9974\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 23s 45us/step - loss: 0.0200 - acc: 0.9980\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 24s 46us/step - loss: 0.0204 - acc: 0.9980\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 23s 46us/step - loss: 0.0304 - acc: 0.9973\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 24s 47us/step - loss: 0.0194 - acc: 0.9980\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 25s 50us/step - loss: 0.0201 - acc: 0.9980\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 24s 46us/step - loss: 0.0203 - acc: 0.9981\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 24s 46us/step - loss: 0.0254 - acc: 0.9977 5s - loss: 0.025 - ETA: 5s - loss:\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 23s 46us/step - loss: 0.0206 - acc: 0.9981\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 25s 48us/step - loss: 0.0226 - acc: 0.9979\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 24s 47us/step - loss: 0.0246 - acc: 0.9979\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 24s 46us/step - loss: 0.0215 - acc: 0.9980\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 24s 47us/step - loss: 0.0173 - acc: 0.9982\n",
      "56861/56861 [==============================] - ETA:  - 1s 20us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 24s 47us/step - loss: 0.0554 - acc: 0.9885\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 24s 47us/step - loss: 0.0456 - acc: 0.9936\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 24s 46us/step - loss: 0.0519 - acc: 0.9936\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 24s 47us/step - loss: 0.0480 - acc: 0.9943\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 25s 50us/step - loss: 0.0372 - acc: 0.9953\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 24s 47us/step - loss: 0.0328 - acc: 0.9961\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 25s 48us/step - loss: 0.0347 - acc: 0.9959\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 24s 47us/step - loss: 0.0327 - acc: 0.9961\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 24s 48us/step - loss: 0.0277 - acc: 0.9967\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 25s 48us/step - loss: 0.0229 - acc: 0.9972\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 24s 47us/step - loss: 0.0258 - acc: 0.9971 0s - loss: 0.0260 - \n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 24s 47us/step - loss: 0.0184 - acc: 0.9978\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 23s 45us/step - loss: 0.0227 - acc: 0.9974\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 18s 35us/step - loss: 0.0284 - acc: 0.9971\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 18s 36us/step - loss: 0.0240 - acc: 0.9975\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 18s 36us/step - loss: 0.0263 - acc: 0.9974\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 18s 35us/step - loss: 0.0204 - acc: 0.9977\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0210 - acc: 0.9979\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 19s 36us/step - loss: 0.0227 - acc: 0.9978\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 18s 36us/step - loss: 0.0197 - acc: 0.9980\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 18s 36us/step - loss: 0.0214 - acc: 0.9979\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 20s 38us/step - loss: 0.0196 - acc: 0.9980\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 18s 36us/step - loss: 0.0249 - acc: 0.9978\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0208 - acc: 0.9981\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0203 - acc: 0.9981\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 19s 36us/step - loss: 0.0177 - acc: 0.9983\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 19s 37us/step - loss: 0.0192 - acc: 0.9983\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 19s 36us/step - loss: 0.0204 - acc: 0.9981 1\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 18s 36us/step - loss: 0.0194 - acc: 0.9982\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 18s 35us/step - loss: 0.0170 - acc: 0.9985 1s -\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 18s 36us/step - loss: 0.0209 - acc: 0.9983 1s - l\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 18s 36us/step - loss: 0.0230 - acc: 0.9980\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 18s 36us/step - loss: 0.0205 - acc: 0.9982\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 18s 36us/step - loss: 0.0181 - acc: 0.9984\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 20s 38us/step - loss: 0.0161 - acc: 0.9986\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 18s 36us/step - loss: 0.0274 - acc: 0.9979\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 18s 36us/step - loss: 0.0211 - acc: 0.9982\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0202 - acc: 0.9982\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 20s 38us/step - loss: 0.0216 - acc: 0.9982\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 20s 38us/step - loss: 0.0194 - acc: 0.9984\n",
      "56861/56861 [==============================] - 1s 17us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0680 - acc: 0.9878\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0492 - acc: 0.9936 0s - loss: 0.0493 - acc: 0.99\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0432 - acc: 0.9942\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0324 - acc: 0.9956\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0290 - acc: 0.9963\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0276 - acc: 0.9966\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 26s 50us/step - loss: 0.0267 - acc: 0.9968\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 22s 43us/step - loss: 0.0248 - acc: 0.9971\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0249 - acc: 0.9972\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0224 - acc: 0.9975\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0262 - acc: 0.9973\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0239 - acc: 0.9975\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0180 - acc: 0.9978\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0259 - acc: 0.9975\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0243 - acc: 0.9976\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 19s 37us/step - loss: 0.0266 - acc: 0.9975\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0246 - acc: 0.9977\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 19s 37us/step - loss: 0.0250 - acc: 0.9977\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0180 - acc: 0.9981\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0172 - acc: 0.9982\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0172 - acc: 0.9983\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 19s 37us/step - loss: 0.0190 - acc: 0.9982\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0189 - acc: 0.9981\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0167 - acc: 0.9983\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0151 - acc: 0.9985\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0161 - acc: 0.9984\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 19s 37us/step - loss: 0.0185 - acc: 0.9983\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0207 - acc: 0.9981\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0135 - acc: 0.9986\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 20s 38us/step - loss: 0.0161 - acc: 0.9985\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 20s 38us/step - loss: 0.0135 - acc: 0.9986\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 19s 37us/step - loss: 0.0179 - acc: 0.9984\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0169 - acc: 0.9984\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0188 - acc: 0.9983\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0176 - acc: 0.9983\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0231 - acc: 0.9981\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0348 - acc: 0.9973\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0189 - acc: 0.9983\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 20s 38us/step - loss: 0.0203 - acc: 0.9982\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0129 - acc: 0.9987\n",
      "56861/56861 [==============================] - 1s 17us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0599 - acc: 0.9884\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0477 - acc: 0.9935\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0417 - acc: 0.9947\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 19s 37us/step - loss: 0.0359 - acc: 0.9956\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0417 - acc: 0.9954\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0295 - acc: 0.9963\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0353 - acc: 0.9963\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 19s 37us/step - loss: 0.0307 - acc: 0.9966\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0250 - acc: 0.9971\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0257 - acc: 0.9971\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0255 - acc: 0.9972\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0320 - acc: 0.9967\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0229 - acc: 0.9974\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0358 - acc: 0.9966\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0262 - acc: 0.9972\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0288 - acc: 0.9971\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 19s 37us/step - loss: 0.0216 - acc: 0.9976\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 20s 38us/step - loss: 0.0236 - acc: 0.9976\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 19s 37us/step - loss: 0.0253 - acc: 0.9974 1s - l\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0231 - acc: 0.9976\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0239 - acc: 0.9975\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0274 - acc: 0.9974\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0243 - acc: 0.9977\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0254 - acc: 0.9975\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 20s 38us/step - loss: 0.0176 - acc: 0.9980\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 19s 37us/step - loss: 0.0180 - acc: 0.9981\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 19s 37us/step - loss: 0.0290 - acc: 0.9975\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0179 - acc: 0.9982\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0234 - acc: 0.9978\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0198 - acc: 0.9980\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0229 - acc: 0.9979\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0181 - acc: 0.9983\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0218 - acc: 0.9981\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0290 - acc: 0.9974\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0255 - acc: 0.9977\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0172 - acc: 0.9983 0s - loss: 0.016\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0258 - acc: 0.9977\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0302 - acc: 0.9975\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0167 - acc: 0.9984\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 19s 38us/step - loss: 0.0327 - acc: 0.9975 0s - loss: 0\n",
      "56861/56861 [==============================] - 1s 19us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 19s 38us/step - loss: 0.0656 - acc: 0.9873\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0531 - acc: 0.9926\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0357 - acc: 0.9947\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0300 - acc: 0.9956\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0291 - acc: 0.9961\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0235 - acc: 0.9967\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0249 - acc: 0.9967\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0218 - acc: 0.9971\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0243 - acc: 0.9969\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0217 - acc: 0.9972\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 19s 38us/step - loss: 0.0252 - acc: 0.9971\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 19s 38us/step - loss: 0.0281 - acc: 0.9970\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0190 - acc: 0.9977\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 19s 36us/step - loss: 0.0195 - acc: 0.9977\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 19s 36us/step - loss: 0.0194 - acc: 0.9976\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0181 - acc: 0.9978\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 19s 36us/step - loss: 0.0268 - acc: 0.9973\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 19s 36us/step - loss: 0.0178 - acc: 0.9979\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0208 - acc: 0.9977\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0280 - acc: 0.9973 0s - loss: 0.0281 - acc: 0.997\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0219 - acc: 0.9978\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0163 - acc: 0.9982\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 19s 36us/step - loss: 0.0173 - acc: 0.9981\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 19s 36us/step - loss: 0.0193 - acc: 0.9980\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0192 - acc: 0.9980\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 19s 38us/step - loss: 0.0191 - acc: 0.9980\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0218 - acc: 0.9979\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 19s 38us/step - loss: 0.0194 - acc: 0.9981\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0253 - acc: 0.9978\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0184 - acc: 0.9983\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0137 - acc: 0.9986\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0172 - acc: 0.9984\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 19s 36us/step - loss: 0.0200 - acc: 0.9982\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 19s 36us/step - loss: 0.0174 - acc: 0.9984\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0135 - acc: 0.9987\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0155 - acc: 0.9985\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 19s 37us/step - loss: 0.0164 - acc: 0.9985\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 19s 38us/step - loss: 0.0156 - acc: 0.9985\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 19s 36us/step - loss: 0.0147 - acc: 0.9986\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 19s 36us/step - loss: 0.0141 - acc: 0.9987\n",
      "56862/56862 [==============================] - 1s 21us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0534 - acc: 0.9890\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0428 - acc: 0.9934\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0414 - acc: 0.9945\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0324 - acc: 0.9955 0s - loss: 0.032\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0284 - acc: 0.9961\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0245 - acc: 0.9967\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0293 - acc: 0.9964\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0289 - acc: 0.9965\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0258 - acc: 0.9968\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0241 - acc: 0.9972\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0279 - acc: 0.9970\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - ETA: 0s - loss: 0.0254 - acc: 0.997 - 22s 43us/step - loss: 0.0254 - acc: 0.9972\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0223 - acc: 0.9974\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0215 - acc: 0.9975\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0213 - acc: 0.9977\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0257 - acc: 0.9974\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0287 - acc: 0.9972\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0237 - acc: 0.9977\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0274 - acc: 0.9974\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0238 - acc: 0.9977\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0185 - acc: 0.9981\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0283 - acc: 0.9974 1s - loss: 0.0292 - acc: 0.997 - ETA: 1s - l\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0215 - acc: 0.9978\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0255 - acc: 0.9977\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0169 - acc: 0.9983\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0179 - acc: 0.9981\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0207 - acc: 0.9980\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0186 - acc: 0.9982\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0159 - acc: 0.9984\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0179 - acc: 0.9983\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0181 - acc: 0.9984\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0163 - acc: 0.9985\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0213 - acc: 0.9981\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0199 - acc: 0.9981\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0185 - acc: 0.9984\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0189 - acc: 0.9983\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0203 - acc: 0.9982\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0208 - acc: 0.9981\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0162 - acc: 0.9985\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0185 - acc: 0.9983\n",
      "56862/56862 [==============================] - 1s 20us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0589 - acc: 0.9880 1s -\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0436 - acc: 0.9935\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0340 - acc: 0.9951\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0294 - acc: 0.9959\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0281 - acc: 0.9963\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0221 - acc: 0.9971\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0207 - acc: 0.9973\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0209 - acc: 0.9972\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0163 - acc: 0.9978\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0183 - acc: 0.9975\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0208 - acc: 0.9975\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0172 - acc: 0.9978\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0197 - acc: 0.9977\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0206 - acc: 0.9977\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0186 - acc: 0.9980\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0259 - acc: 0.9973\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0197 - acc: 0.9978\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0180 - acc: 0.9981\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 19s 38us/step - loss: 0.0153 - acc: 0.9982\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 20s 38us/step - loss: 0.0176 - acc: 0.9981\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0128 - acc: 0.9985\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0128 - acc: 0.9985\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 20s 38us/step - loss: 0.0137 - acc: 0.9985\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0118 - acc: 0.9986\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0178 - acc: 0.9983\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0191 - acc: 0.9982\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0154 - acc: 0.9985\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0203 - acc: 0.9981 1s\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0150 - acc: 0.9984\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0144 - acc: 0.9986\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0173 - acc: 0.9984\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0214 - acc: 0.9981\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0156 - acc: 0.9985\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 20s 38us/step - loss: 0.0141 - acc: 0.9986\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0127 - acc: 0.9987\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0150 - acc: 0.9986\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0140 - acc: 0.9986\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 20s 39us/step - loss: 0.0143 - acc: 0.9987\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 20s 40us/step - loss: 0.0124 - acc: 0.9988\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 19s 38us/step - loss: 0.0183 - acc: 0.9984\n",
      "56862/56862 [==============================] - 1s 22us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0562 - acc: 0.9887 0s - loss: 0.\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0472 - acc: 0.9930\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0453 - acc: 0.9938\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0390 - acc: 0.9947\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0329 - acc: 0.9955 0s - loss: 0.0331 - ac\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0341 - acc: 0.9958\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0342 - acc: 0.9961\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0459 - acc: 0.9954\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0356 - acc: 0.9964\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0343 - acc: 0.9966\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0325 - acc: 0.9963\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0266 - acc: 0.9971\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0250 - acc: 0.9975\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0295 - acc: 0.9973\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0512 - acc: 0.9959\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0342 - acc: 0.9971\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0381 - acc: 0.9968\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0266 - acc: 0.9975\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0342 - acc: 0.9970\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0265 - acc: 0.9975\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0294 - acc: 0.9975\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0238 - acc: 0.9977\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0208 - acc: 0.9980\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0207 - acc: 0.9982\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0260 - acc: 0.9977\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0228 - acc: 0.9979\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0200 - acc: 0.9982\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0228 - acc: 0.9980\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0292 - acc: 0.9977\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0221 - acc: 0.9982\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0181 - acc: 0.9985\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0316 - acc: 0.9976\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0238 - acc: 0.9981\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0182 - acc: 0.9984\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0370 - acc: 0.9973\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0239 - acc: 0.9980\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0199 - acc: 0.9983\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0175 - acc: 0.9985\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0374 - acc: 0.9973\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0289 - acc: 0.9978\n",
      "56862/56862 [==============================] - 1s 19us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0753 - acc: 0.9870\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0457 - acc: 0.9934\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0349 - acc: 0.9946\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0339 - acc: 0.9951\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0276 - acc: 0.9960\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0295 - acc: 0.9961\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0281 - acc: 0.9964\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0281 - acc: 0.9965\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0248 - acc: 0.9967\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0253 - acc: 0.9967\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0225 - acc: 0.9971\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0229 - acc: 0.9971\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0221 - acc: 0.9973\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0215 - acc: 0.9975\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0244 - acc: 0.9973\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0209 - acc: 0.9976\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0196 - acc: 0.9978\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0169 - acc: 0.9980\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0228 - acc: 0.9976\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0194 - acc: 0.9979\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0197 - acc: 0.9979\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0168 - acc: 0.9982\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0224 - acc: 0.9978\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 22s 42us/step - loss: 0.0218 - acc: 0.9978\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0184 - acc: 0.9981\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0181 - acc: 0.9982\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0219 - acc: 0.9978\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0179 - acc: 0.9983\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0177 - acc: 0.9982\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0208 - acc: 0.9980\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0156 - acc: 0.9984\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0269 - acc: 0.9977\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0205 - acc: 0.9981\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0179 - acc: 0.9983 1s - loss\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 21s 42us/step - loss: 0.0297 - acc: 0.9975\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 21s 40us/step - loss: 0.0143 - acc: 0.9986\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0211 - acc: 0.9981\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0217 - acc: 0.9980\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0221 - acc: 0.9980\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 21s 41us/step - loss: 0.0203 - acc: 0.9982\n",
      "56862/56862 [==============================] - 1s 22us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0635 - acc: 0.9859\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0572 - acc: 0.9917\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0476 - acc: 0.9936\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0425 - acc: 0.9944\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 20s 38us/step - loss: 0.0491 - acc: 0.9944\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0415 - acc: 0.9955\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0389 - acc: 0.9955\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0319 - acc: 0.9963\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0450 - acc: 0.9956\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0337 - acc: 0.9963\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0309 - acc: 0.9966\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0392 - acc: 0.9962\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0278 - acc: 0.9972\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0290 - acc: 0.9971\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0291 - acc: 0.9972\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0307 - acc: 0.9971\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0285 - acc: 0.9974\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0291 - acc: 0.9973\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0299 - acc: 0.9973 0s - loss: 0.0299 - acc: 0.99\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0279 - acc: 0.9974\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0245 - acc: 0.9978\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0297 - acc: 0.9976\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0266 - acc: 0.9977\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 23s 44us/step - loss: 0.0290 - acc: 0.9975\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0235 - acc: 0.9979\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0229 - acc: 0.9979\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0228 - acc: 0.9981\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0242 - acc: 0.9978\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0232 - acc: 0.9981\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0220 - acc: 0.9981 1s - los\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0214 - acc: 0.9981\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0257 - acc: 0.9978\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0254 - acc: 0.9978\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 20s 38us/step - loss: 0.0266 - acc: 0.9979\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0368 - acc: 0.9972\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0251 - acc: 0.9979\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 20s 38us/step - loss: 0.0383 - acc: 0.9972\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0254 - acc: 0.9980\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0278 - acc: 0.9978\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0228 - acc: 0.9981\n",
      "56861/56861 [==============================] - 1s 20us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0503 - acc: 0.9888\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0380 - acc: 0.9939\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0405 - acc: 0.9948\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0336 - acc: 0.9955\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0297 - acc: 0.9960\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0302 - acc: 0.9963\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0276 - acc: 0.9966\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0232 - acc: 0.9970\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0219 - acc: 0.9973 1s - loss: 0.0223 - acc: 0.997 - ETA: 0s - loss:\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0226 - acc: 0.9972\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0211 - acc: 0.9975\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0232 - acc: 0.9973\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0218 - acc: 0.9975\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0203 - acc: 0.9977\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0210 - acc: 0.9979\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0218 - acc: 0.9977\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0163 - acc: 0.9981\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0216 - acc: 0.9979\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0217 - acc: 0.9979\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0200 - acc: 0.9981\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0317 - acc: 0.9973\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0230 - acc: 0.9979\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0232 - acc: 0.9978 1s - \n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0261 - acc: 0.9977\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0237 - acc: 0.9977\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0170 - acc: 0.9983\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0233 - acc: 0.9981\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 22s 43us/step - loss: 0.0243 - acc: 0.9979 0s - loss: 0.0243 - acc: 0.9 - ETA: 0s - loss: 0.0244 - acc: 0\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0198 - acc: 0.9982\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0209 - acc: 0.9981\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0277 - acc: 0.9975\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0192 - acc: 0.9982\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 22s 43us/step - loss: 0.0147 - acc: 0.9986\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0190 - acc: 0.9982\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0173 - acc: 0.9984\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0248 - acc: 0.9979\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0200 - acc: 0.9982\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0215 - acc: 0.9982\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0245 - acc: 0.9980\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0161 - acc: 0.9985\n",
      "56861/56861 [==============================] - 1s 20us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0630 - acc: 0.9877\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0470 - acc: 0.9931\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0400 - acc: 0.9943\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0364 - acc: 0.9951\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0413 - acc: 0.9949 0s - loss: 0\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0372 - acc: 0.9954\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0413 - acc: 0.9953\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0397 - acc: 0.9957\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0355 - acc: 0.9961\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0355 - acc: 0.9960\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0321 - acc: 0.9962\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0392 - acc: 0.9959\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0380 - acc: 0.9960\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0330 - acc: 0.9963\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0329 - acc: 0.9963\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0281 - acc: 0.9969\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0279 - acc: 0.9968\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0333 - acc: 0.9965\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0299 - acc: 0.9969\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0360 - acc: 0.9964\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0337 - acc: 0.9966\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0325 - acc: 0.9967\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0314 - acc: 0.9968\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0373 - acc: 0.9964 1s - lo\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0328 - acc: 0.9967\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0286 - acc: 0.9970\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0321 - acc: 0.9969\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0335 - acc: 0.9967\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0385 - acc: 0.9964\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0370 - acc: 0.9966\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0364 - acc: 0.9967\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0333 - acc: 0.9971\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0305 - acc: 0.9972\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0323 - acc: 0.9972\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0293 - acc: 0.9974\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0364 - acc: 0.9970\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0379 - acc: 0.9967\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0302 - acc: 0.9972\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0378 - acc: 0.9969\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 20s 39us/step - loss: 0.0402 - acc: 0.9966\n",
      "56861/56861 [==============================] - 1s 21us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0580 - acc: 0.9882\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0335 - acc: 0.9945\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0302 - acc: 0.9958\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0275 - acc: 0.9961\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0207 - acc: 0.9970\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0221 - acc: 0.9971\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0317 - acc: 0.9966\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0264 - acc: 0.9971\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0269 - acc: 0.9971\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0233 - acc: 0.9975\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0224 - acc: 0.9975\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0204 - acc: 0.9977\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0171 - acc: 0.9980\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0151 - acc: 0.9982\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 23s 45us/step - loss: 0.0155 - acc: 0.9982\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0190 - acc: 0.9979\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0155 - acc: 0.9981\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0139 - acc: 0.9984\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0146 - acc: 0.9984\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0169 - acc: 0.9983\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0130 - acc: 0.9986\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0123 - acc: 0.9986\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0130 - acc: 0.9985\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0181 - acc: 0.9983\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0171 - acc: 0.9984\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0173 - acc: 0.9983\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0137 - acc: 0.9985 0s - loss: 0.0138 - a\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0158 - acc: 0.9984\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0161 - acc: 0.9984\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0150 - acc: 0.9985\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0135 - acc: 0.9986\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0141 - acc: 0.9986\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0159 - acc: 0.9984\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0138 - acc: 0.9986\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0135 - acc: 0.9986\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0169 - acc: 0.9984\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0112 - acc: 0.9988\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0153 - acc: 0.9985\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 20s 40us/step - loss: 0.0117 - acc: 0.9989\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0185 - acc: 0.9983\n",
      "56861/56861 [==============================] - 1s 22us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0639 - acc: 0.9881\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0532 - acc: 0.9929\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0436 - acc: 0.9943\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0318 - acc: 0.9957\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0420 - acc: 0.9952\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0331 - acc: 0.9961\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0344 - acc: 0.9963\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0287 - acc: 0.9968\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0280 - acc: 0.9969\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0315 - acc: 0.9966\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0251 - acc: 0.9971\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0256 - acc: 0.9972\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0211 - acc: 0.9976\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0228 - acc: 0.9975\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0203 - acc: 0.9978\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0207 - acc: 0.9978\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0253 - acc: 0.9975\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0255 - acc: 0.9975\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0255 - acc: 0.9975\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0260 - acc: 0.9975\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0253 - acc: 0.9976\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0293 - acc: 0.9975\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0206 - acc: 0.9979\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0198 - acc: 0.9980\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0241 - acc: 0.9979\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0229 - acc: 0.9979\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0216 - acc: 0.9980 0s - loss: 0\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0190 - acc: 0.9982\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0203 - acc: 0.9981\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 21s 42us/step - loss: 0.0183 - acc: 0.9982\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0213 - acc: 0.9981\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 21s 41us/step - loss: 0.0190 - acc: 0.9982\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 21s 40us/step - loss: 0.0222 - acc: 0.9980\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 22s 42us/step - loss: 0.0190 - acc: 0.9983\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 22s 43us/step - loss: 0.0276 - acc: 0.9978\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 22s 43us/step - loss: 0.0161 - acc: 0.9985\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 22s 43us/step - loss: 0.0275 - acc: 0.9978\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 23s 45us/step - loss: 0.0299 - acc: 0.9976\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 22s 43us/step - loss: 0.0263 - acc: 0.9979\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 22s 43us/step - loss: 0.0259 - acc: 0.9978\n",
      "56861/56861 [==============================] - 1s 23us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0574 - acc: 0.9878\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0485 - acc: 0.9930\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0377 - acc: 0.9947\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0375 - acc: 0.9951\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0327 - acc: 0.9956\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0291 - acc: 0.9961\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0290 - acc: 0.9961\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0254 - acc: 0.9966\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0266 - acc: 0.9967\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0241 - acc: 0.9969\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0236 - acc: 0.9972\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0227 - acc: 0.9973\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0187 - acc: 0.9977\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0199 - acc: 0.9976\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0164 - acc: 0.9980\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0219 - acc: 0.9977\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0212 - acc: 0.9977\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0194 - acc: 0.9979\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0200 - acc: 0.9979 1s \n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0250 - acc: 0.9976\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0199 - acc: 0.9979\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0182 - acc: 0.9982 0s - loss: 0.0181 - \n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0200 - acc: 0.9981\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 23s 46us/step - loss: 0.0231 - acc: 0.9978\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0173 - acc: 0.9982\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0151 - acc: 0.9984\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0183 - acc: 0.9983\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0222 - acc: 0.9981\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0216 - acc: 0.9981\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0224 - acc: 0.9980\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0234 - acc: 0.9979\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0234 - acc: 0.9980\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0235 - acc: 0.9979\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0187 - acc: 0.9983\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0206 - acc: 0.9982\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0243 - acc: 0.9979 0s - loss: 0.02\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0198 - acc: 0.9982\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 24s 46us/step - loss: 0.0208 - acc: 0.9982\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0210 - acc: 0.9982\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0163 - acc: 0.9985\n",
      "56862/56862 [==============================] - 1s 24us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0543 - acc: 0.9886\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0414 - acc: 0.9933\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0405 - acc: 0.9943\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0356 - acc: 0.9951\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0330 - acc: 0.9955\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0320 - acc: 0.9959\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0351 - acc: 0.9959\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0325 - acc: 0.9964\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0304 - acc: 0.9967\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0257 - acc: 0.9969\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0284 - acc: 0.9968\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0251 - acc: 0.9972\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0281 - acc: 0.9971\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0196 - acc: 0.9979\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0217 - acc: 0.9977 0s - loss: 0.0217 - acc: 0\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0181 - acc: 0.9980\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0180 - acc: 0.9980 1s - loss:\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0215 - acc: 0.9978\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0221 - acc: 0.9978\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0178 - acc: 0.9981\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0222 - acc: 0.9978\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0210 - acc: 0.9980\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0177 - acc: 0.9981\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 23s 45us/step - loss: 0.0197 - acc: 0.9980\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0252 - acc: 0.9977\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0174 - acc: 0.9983\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0197 - acc: 0.9982\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0201 - acc: 0.9982\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0188 - acc: 0.9983\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0179 - acc: 0.9983\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0191 - acc: 0.9982 0s - loss: 0.0192 - acc: 0.\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0189 - acc: 0.9984\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0164 - acc: 0.9984\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0253 - acc: 0.9979\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 23s 44us/step - loss: 0.0206 - acc: 0.9982\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 22s 43us/step - loss: 0.0155 - acc: 0.9985\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 22s 44us/step - loss: 0.0191 - acc: 0.9984\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 24s 46us/step - loss: 0.0181 - acc: 0.9984\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 24s 47us/step - loss: 0.0178 - acc: 0.9984\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0196 - acc: 0.9983 1s - loss: 0\n",
      "56862/56862 [==============================] - 1s 25us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0531 - acc: 0.9889\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 27s 54us/step - loss: 0.0332 - acc: 0.9945\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0307 - acc: 0.9955\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0292 - acc: 0.9959\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0276 - acc: 0.9962\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0270 - acc: 0.9966\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0287 - acc: 0.9966\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - ETA: 0s - loss: 0.0291 - acc: 0.996 - 30s 58us/step - loss: 0.0291 - acc: 0.9968\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 31s 62us/step - loss: 0.0302 - acc: 0.9967\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0273 - acc: 0.9969\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0261 - acc: 0.9970\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0186 - acc: 0.9976\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 29s 58us/step - loss: 0.0203 - acc: 0.9977\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0230 - acc: 0.9975\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0189 - acc: 0.9978\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0196 - acc: 0.9978\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0185 - acc: 0.9978\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0165 - acc: 0.9981\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0154 - acc: 0.9982\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0199 - acc: 0.9979\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0167 - acc: 0.9981\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0212 - acc: 0.9979\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0192 - acc: 0.9981\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0192 - acc: 0.9979\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0209 - acc: 0.9979\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0258 - acc: 0.9977\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0154 - acc: 0.9984\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0214 - acc: 0.9979\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0175 - acc: 0.9982\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0198 - acc: 0.9982\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0185 - acc: 0.9982 0s - loss: 0.0186 - acc: 0.99\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 28s 56us/step - loss: 0.0175 - acc: 0.9983\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0239 - acc: 0.9978\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 26s 50us/step - loss: 0.0187 - acc: 0.9982\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0210 - acc: 0.9982\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0230 - acc: 0.9980\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0169 - acc: 0.9984\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0200 - acc: 0.9982\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 28s 56us/step - loss: 0.0187 - acc: 0.9983\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0193 - acc: 0.9982\n",
      "56862/56862 [==============================] - 1s 26us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0642 - acc: 0.9879\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0418 - acc: 0.9938\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0535 - acc: 0.9938\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0417 - acc: 0.9950\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 27s 54us/step - loss: 0.0410 - acc: 0.9954\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 27s 54us/step - loss: 0.0483 - acc: 0.9951 1s - loss: 0.0469 - acc: 0.9 - ETA: 1s - loss\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0424 - acc: 0.9956\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 27s 52us/step - loss: 0.0325 - acc: 0.9964\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0342 - acc: 0.9963\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0225 - acc: 0.9974\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0253 - acc: 0.9972 0s - loss: 0.0252 - acc\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 27s 54us/step - loss: 0.0261 - acc: 0.9973\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0324 - acc: 0.9970\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0197 - acc: 0.9979\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 27s 52us/step - loss: 0.0279 - acc: 0.9974\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0231 - acc: 0.9978\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0184 - acc: 0.9982\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0280 - acc: 0.9976\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0191 - acc: 0.9982\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 28s 56us/step - loss: 0.0221 - acc: 0.9980\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0216 - acc: 0.9980\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0259 - acc: 0.9976\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0216 - acc: 0.9979\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0185 - acc: 0.9982\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0212 - acc: 0.9980\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0199 - acc: 0.9982\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0209 - acc: 0.9982\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0225 - acc: 0.9981\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0165 - acc: 0.9985\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 28s 56us/step - loss: 0.0235 - acc: 0.9981\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0221 - acc: 0.9982\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0170 - acc: 0.9983\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0159 - acc: 0.9984\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0207 - acc: 0.9982\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0200 - acc: 0.9984  - ETA: 0s - loss: 0.0201 - ac\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 29s 58us/step - loss: 0.0180 - acc: 0.9985\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 27s 52us/step - loss: 0.0245 - acc: 0.9981\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0176 - acc: 0.9986\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0350 - acc: 0.9974\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0190 - acc: 0.9984\n",
      "56862/56862 [==============================] - 2s 36us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0654 - acc: 0.9878\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0513 - acc: 0.9927\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0337 - acc: 0.9950 1s - loss: 0.0337 - acc: 0.995 - ETA: \n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0305 - acc: 0.9957\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 27s 52us/step - loss: 0.0301 - acc: 0.9960\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0276 - acc: 0.9964\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0345 - acc: 0.9962\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 26s 52us/step - loss: 0.0330 - acc: 0.9964\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0245 - acc: 0.9970\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 27s 52us/step - loss: 0.0207 - acc: 0.9974\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0355 - acc: 0.9964\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0222 - acc: 0.9974\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0202 - acc: 0.9975\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0207 - acc: 0.9976\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0216 - acc: 0.9975\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0254 - acc: 0.9974\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0253 - acc: 0.9974\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0222 - acc: 0.9976\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0170 - acc: 0.9979\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0173 - acc: 0.9979\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 28s 56us/step - loss: 0.0232 - acc: 0.9976\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0198 - acc: 0.9979\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0185 - acc: 0.9980\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 28s 56us/step - loss: 0.0212 - acc: 0.9977\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 26s 50us/step - loss: 0.0194 - acc: 0.9979\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0237 - acc: 0.9976\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0233 - acc: 0.9977\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0217 - acc: 0.9979\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0218 - acc: 0.9978\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 27s 54us/step - loss: 0.0196 - acc: 0.9981\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0269 - acc: 0.9975\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0174 - acc: 0.9981\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0188 - acc: 0.9980\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0199 - acc: 0.9981\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0199 - acc: 0.9979\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0258 - acc: 0.9976\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 27s 52us/step - loss: 0.0227 - acc: 0.9978\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0184 - acc: 0.9980\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0190 - acc: 0.9981\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 33s 64us/step - loss: 0.0191 - acc: 0.9982\n",
      "56862/56862 [==============================] - 2s 37us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 36s 71us/step - loss: 0.0609 - acc: 0.9883\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0453 - acc: 0.9938\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 34s 67us/step - loss: 0.0424 - acc: 0.9945\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 34s 67us/step - loss: 0.0478 - acc: 0.9943\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0432 - acc: 0.9951\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0361 - acc: 0.9959\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0334 - acc: 0.9963\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0356 - acc: 0.9961\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0291 - acc: 0.9968\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0391 - acc: 0.9963\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 27s 53us/step - loss: 0.0419 - acc: 0.9961\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0319 - acc: 0.9968\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 28s 55us/step - loss: 0.0281 - acc: 0.9972\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0300 - acc: 0.9972\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0297 - acc: 0.9971\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0295 - acc: 0.9972\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 29s 58us/step - loss: 0.0258 - acc: 0.9977\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 29s 58us/step - loss: 0.0286 - acc: 0.9974\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0257 - acc: 0.9978\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 28s 56us/step - loss: 0.0245 - acc: 0.9978\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0359 - acc: 0.9971\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 28s 55us/step - loss: 0.0246 - acc: 0.9978\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0429 - acc: 0.9966\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 29s 58us/step - loss: 0.0317 - acc: 0.9973\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0333 - acc: 0.9973\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0263 - acc: 0.9975\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0241 - acc: 0.9978\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0230 - acc: 0.9980 1s\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0259 - acc: 0.9978\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 28s 55us/step - loss: 0.0265 - acc: 0.9978\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0323 - acc: 0.9973\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0321 - acc: 0.9974\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0248 - acc: 0.9979\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0340 - acc: 0.9974\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0204 - acc: 0.9984\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0251 - acc: 0.9980\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0329 - acc: 0.9974\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0343 - acc: 0.9974\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0263 - acc: 0.9977\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0289 - acc: 0.9976\n",
      "56861/56861 [==============================] - 2s 33us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0576 - acc: 0.9882\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 53s 104us/step - loss: 0.0521 - acc: 0.9925\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 106s 208us/step - loss: 0.0542 - acc: 0.9934\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 109s 214us/step - loss: 0.0417 - acc: 0.9948\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 99s 193us/step - loss: 0.0419 - acc: 0.9947\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 96s 188us/step - loss: 0.0388 - acc: 0.9953\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 94s 184us/step - loss: 0.0338 - acc: 0.9959\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 90s 176us/step - loss: 0.0334 - acc: 0.9961\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 89s 175us/step - loss: 0.0324 - acc: 0.9963\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 91s 177us/step - loss: 0.0378 - acc: 0.9958\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 89s 175us/step - loss: 0.0279 - acc: 0.9967\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 90s 176us/step - loss: 0.0281 - acc: 0.9969\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 90s 175us/step - loss: 0.0247 - acc: 0.9972\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 89s 174us/step - loss: 0.0285 - acc: 0.9970\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 89s 174us/step - loss: 0.0236 - acc: 0.9974\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 91s 177us/step - loss: 0.0226 - acc: 0.9974\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 91s 178us/step - loss: 0.0248 - acc: 0.9973\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 88s 172us/step - loss: 0.0206 - acc: 0.9978\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 93s 183us/step - loss: 0.0239 - acc: 0.9975\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 90s 176us/step - loss: 0.0284 - acc: 0.9972\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 87s 170us/step - loss: 0.0271 - acc: 0.9973\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 89s 174us/step - loss: 0.0349 - acc: 0.9969\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 90s 176us/step - loss: 0.0235 - acc: 0.9976\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 88s 173us/step - loss: 0.0261 - acc: 0.9975\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 89s 174us/step - loss: 0.0213 - acc: 0.9978\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 99s 194us/step - loss: 0.0250 - acc: 0.9976\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 117s 228us/step - loss: 0.0250 - acc: 0.9975\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 116s 227us/step - loss: 0.0248 - acc: 0.9976\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 144s 282us/step - loss: 0.0211 - acc: 0.9980\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 143s 279us/step - loss: 0.0232 - acc: 0.9978\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 123s 240us/step - loss: 0.0248 - acc: 0.9978\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 106s 208us/step - loss: 0.0256 - acc: 0.9977\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 85s 167us/step - loss: 0.0268 - acc: 0.9977\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 77s 151us/step - loss: 0.0286 - acc: 0.9976\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 76s 149us/step - loss: 0.0335 - acc: 0.9972\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 80s 156us/step - loss: 0.0276 - acc: 0.9977\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 82s 160us/step - loss: 0.0263 - acc: 0.9977\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 80s 157us/step - loss: 0.0269 - acc: 0.9977\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 90s 176us/step - loss: 0.0264 - acc: 0.9977\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 80s 156us/step - loss: 0.0251 - acc: 0.9979\n",
      "56861/56861 [==============================] - 6s 98us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 82s 161us/step - loss: 0.0633 - acc: 0.9881\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 78s 152us/step - loss: 0.0400 - acc: 0.9939\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 78s 152us/step - loss: 0.0318 - acc: 0.9952\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 79s 153us/step - loss: 0.0296 - acc: 0.9958\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 77s 151us/step - loss: 0.0312 - acc: 0.9960\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 78s 153us/step - loss: 0.0269 - acc: 0.9966\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 78s 151us/step - loss: 0.0323 - acc: 0.9962\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 80s 156us/step - loss: 0.0253 - acc: 0.9968\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 77s 151us/step - loss: 0.0260 - acc: 0.9969\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 78s 153us/step - loss: 0.0270 - acc: 0.9969\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 78s 152us/step - loss: 0.0271 - acc: 0.9969\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 76s 149us/step - loss: 0.0286 - acc: 0.9969\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 78s 153us/step - loss: 0.0241 - acc: 0.9974\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 78s 152us/step - loss: 0.0283 - acc: 0.9969\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - ETA: 0s - loss: 0.0197 - acc: 0.997 - 77s 151us/step - loss: 0.0197 - acc: 0.9977\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 77s 151us/step - loss: 0.0198 - acc: 0.9978\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 78s 152us/step - loss: 0.0248 - acc: 0.9973\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 85s 165us/step - loss: 0.0243 - acc: 0.9975\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 78s 152us/step - loss: 0.0187 - acc: 0.9979\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 80s 156us/step - loss: 0.0214 - acc: 0.9977\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 81s 157us/step - loss: 0.0225 - acc: 0.9976\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 82s 160us/step - loss: 0.0222 - acc: 0.9977\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 77s 150us/step - loss: 0.0196 - acc: 0.9980\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 91s 177us/step - loss: 0.0206 - acc: 0.9980\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 110s 216us/step - loss: 0.0199 - acc: 0.9980\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 99s 194us/step - loss: 0.0182 - acc: 0.9981\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 99s 194us/step - loss: 0.0211 - acc: 0.9979\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 88s 173us/step - loss: 0.0216 - acc: 0.9979\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 84s 164us/step - loss: 0.0191 - acc: 0.9980\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 72s 141us/step - loss: 0.0190 - acc: 0.9981\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 74s 144us/step - loss: 0.0197 - acc: 0.9981\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 75s 146us/step - loss: 0.0248 - acc: 0.9978\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 75s 147us/step - loss: 0.0177 - acc: 0.9982\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 95s 185us/step - loss: 0.0202 - acc: 0.9982\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 96s 187us/step - loss: 0.0235 - acc: 0.9980\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 103s 200us/step - loss: 0.0176 - acc: 0.9983\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 95s 186us/step - loss: 0.0211 - acc: 0.9981\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 93s 181us/step - loss: 0.0171 - acc: 0.9985\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 86s 169us/step - loss: 0.0163 - acc: 0.9986\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 88s 172us/step - loss: 0.0273 - acc: 0.9978\n",
      "56861/56861 [==============================] - 5s 94us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 80s 157us/step - loss: 0.0514 - acc: 0.9890\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 74s 144us/step - loss: 0.0323 - acc: 0.9945\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 78s 152us/step - loss: 0.0297 - acc: 0.9953\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 79s 155us/step - loss: 0.0292 - acc: 0.9958\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 88s 171us/step - loss: 0.0251 - acc: 0.9964\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 89s 174us/step - loss: 0.0215 - acc: 0.9969\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 91s 178us/step - loss: 0.0228 - acc: 0.9970\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 95s 187us/step - loss: 0.0195 - acc: 0.99741s \n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 81s 158us/step - loss: 0.0205 - acc: 0.9973\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 88s 173us/step - loss: 0.0190 - acc: 0.9975\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 76s 148us/step - loss: 0.0250 - acc: 0.9973\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 70s 137us/step - loss: 0.0209 - acc: 0.9976\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 62s 121us/step - loss: 0.0174 - acc: 0.9978\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 72s 140us/step - loss: 0.0249 - acc: 0.9975\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 76s 149us/step - loss: 0.0290 - acc: 0.9972\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 70s 136us/step - loss: 0.0287 - acc: 0.9973\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 66s 130us/step - loss: 0.0195 - acc: 0.9980\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 65s 127us/step - loss: 0.0222 - acc: 0.9978\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 67s 131us/step - loss: 0.0167 - acc: 0.9982\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 69s 136us/step - loss: 0.0151 - acc: 0.9984\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 67s 131us/step - loss: 0.0155 - acc: 0.9984\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 65s 127us/step - loss: 0.0156 - acc: 0.9983\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 68s 132us/step - loss: 0.0137 - acc: 0.9985\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 69s 135us/step - loss: 0.0175 - acc: 0.9982\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 72s 141us/step - loss: 0.0140 - acc: 0.9985\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 67s 131us/step - loss: 0.0185 - acc: 0.9982\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 67s 131us/step - loss: 0.0156 - acc: 0.9984\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 64s 126us/step - loss: 0.0152 - acc: 0.9984\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 64s 126us/step - loss: 0.0169 - acc: 0.9984\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 68s 132us/step - loss: 0.0132 - acc: 0.9987\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 65s 126us/step - loss: 0.0158 - acc: 0.9985\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 67s 130us/step - loss: 0.0226 - acc: 0.9980\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 66s 128us/step - loss: 0.0169 - acc: 0.9984\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 69s 135us/step - loss: 0.0175 - acc: 0.9984\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 78s 152us/step - loss: 0.0186 - acc: 0.9984\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 66s 129us/step - loss: 0.0167 - acc: 0.9985\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 68s 132us/step - loss: 0.0193 - acc: 0.9983\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 69s 134us/step - loss: 0.0206 - acc: 0.9983\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 70s 137us/step - loss: 0.0178 - acc: 0.9984\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 71s 138us/step - loss: 0.0178 - acc: 0.9985\n",
      "56861/56861 [==============================] - 6s 97us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 73s 142us/step - loss: 0.0560 - acc: 0.9885\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 79s 154us/step - loss: 0.0507 - acc: 0.9931\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 87s 171us/step - loss: 0.0400 - acc: 0.99470s - loss: 0.0401 - acc:\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 92s 180us/step - loss: 0.0385 - acc: 0.9951\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 78s 152us/step - loss: 0.0388 - acc: 0.9955\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 65s 126us/step - loss: 0.0559 - acc: 0.9946\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 62s 121us/step - loss: 0.0271 - acc: 0.9966\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 62s 121us/step - loss: 0.0298 - acc: 0.9965\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 65s 127us/step - loss: 0.0368 - acc: 0.9964\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 65s 128us/step - loss: 0.0296 - acc: 0.9967\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 64s 126us/step - loss: 0.0256 - acc: 0.9971\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 64s 125us/step - loss: 0.0243 - acc: 0.9973\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 62s 121us/step - loss: 0.0214 - acc: 0.9977\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 63s 122us/step - loss: 0.0256 - acc: 0.9974\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 63s 122us/step - loss: 0.0292 - acc: 0.9972\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 64s 125us/step - loss: 0.0286 - acc: 0.9974\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 62s 121us/step - loss: 0.0304 - acc: 0.9973\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 61s 120us/step - loss: 0.0251 - acc: 0.9976\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 63s 124us/step - loss: 0.0258 - acc: 0.9974\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 62s 121us/step - loss: 0.0248 - acc: 0.9976\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 65s 126us/step - loss: 0.0210 - acc: 0.9979\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 62s 121us/step - loss: 0.0243 - acc: 0.9977\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 61s 120us/step - loss: 0.0218 - acc: 0.9978\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 66s 129us/step - loss: 0.0194 - acc: 0.9981\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 77s 150us/step - loss: 0.0159 - acc: 0.9984\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 74s 144us/step - loss: 0.0200 - acc: 0.9980\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 86s 167us/step - loss: 0.0175 - acc: 0.9983\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 80s 155us/step - loss: 0.0232 - acc: 0.9980\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 84s 165us/step - loss: 0.0199 - acc: 0.9981\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 76s 148us/step - loss: 0.0373 - acc: 0.9970\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 72s 141us/step - loss: 0.0198 - acc: 0.9982\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 67s 131us/step - loss: 0.0264 - acc: 0.9977\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 69s 135us/step - loss: 0.0226 - acc: 0.9980\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 71s 138us/step - loss: 0.0261 - acc: 0.9978\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 68s 132us/step - loss: 0.0266 - acc: 0.9978\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 65s 128us/step - loss: 0.0242 - acc: 0.9980\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 70s 138us/step - loss: 0.0180 - acc: 0.9984\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 67s 131us/step - loss: 0.0216 - acc: 0.9981\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 65s 128us/step - loss: 0.0197 - acc: 0.9983\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 66s 128us/step - loss: 0.0204 - acc: 0.9982\n",
      "56861/56861 [==============================] - 5s 86us/step\n"
     ]
    }
   ],
   "source": [
    "#generate 30 samples\n",
    "for _ in range(0,3):\n",
    "    seed = _\n",
    "    np.random.seed(seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    for train, test in kfold.split(X, y):\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Dense(28, input_shape=(28,), activation='relu' ))\n",
    "        model.add(keras.layers.Dense(2,  activation='softmax' ))\n",
    "        model.compile(keras.optimizers.Adam(lr=0.04), 'categorical_crossentropy', metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        baseline_history = model.fit(X[train], keras.utils.to_categorical(y[train],num_classes=None) , epochs=40, verbose=1)\n",
    "        #print(\"iteration-{} complete!!!\".format(_))\n",
    "        test_loss, test_acc = model.evaluate(X[test], keras.utils.to_categorical(y[test],num_classes=None))\n",
    "        results_control_evaluation_accuracy.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.99813583764201053,\n",
       " 0.99695754634026235,\n",
       " 0.99885688157293095,\n",
       " 0.99788962751925714,\n",
       " 0.99829411557806624,\n",
       " 0.99880410122931362,\n",
       " 0.99825891208385364,\n",
       " 0.99570883382283115,\n",
       " 0.99889203496245227,\n",
       " 0.9985754735231529,\n",
       " 0.99797755970595481,\n",
       " 0.99906791882100521,\n",
       " 0.99859308501283806,\n",
       " 0.9983820477647638,\n",
       " 0.99845239351412196,\n",
       " 0.99854030002989747,\n",
       " 0.99859306026978067,\n",
       " 0.99665851814072914,\n",
       " 0.99453052179877244,\n",
       " 0.99729164101932788,\n",
       " 0.99876894938623328,\n",
       " 0.99834687489008478,\n",
       " 0.99852273926348001,\n",
       " 0.99894481375962862,\n",
       " 0.99820618339136857,\n",
       " 0.99736198800583875,\n",
       " 0.99787200365804329,\n",
       " 0.99824132533722587,\n",
       " 0.99861064701640845,\n",
       " 0.99848753979001426]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_control_evaluation_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental Arm with reduced number of neurons in the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_history = None\n",
    "results_experiment_evaluation_accuracy= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_124 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 33s 65us/step - loss: 0.0602 - acc: 0.9863\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0514 - acc: 0.9920\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0420 - acc: 0.9935\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0298 - acc: 0.9951\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0299 - acc: 0.9955\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0267 - acc: 0.9959\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0258 - acc: 0.9962\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0240 - acc: 0.9963\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0242 - acc: 0.9964\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0206 - acc: 0.9969\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0253 - acc: 0.9967\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0248 - acc: 0.9966\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0228 - acc: 0.9969\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0224 - acc: 0.9969\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0230 - acc: 0.9968\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0211 - acc: 0.9971\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 28s 54us/step - loss: 0.0305 - acc: 0.9965\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0207 - acc: 0.9972\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0238 - acc: 0.9971\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 28s 55us/step - loss: 0.0255 - acc: 0.9969\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0206 - acc: 0.9972\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0216 - acc: 0.9973\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0193 - acc: 0.9975\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 35s 68us/step - loss: 0.0239 - acc: 0.9972\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 34s 65us/step - loss: 0.0220 - acc: 0.9975\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0208 - acc: 0.9975\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0189 - acc: 0.9977\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0177 - acc: 0.9979\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 29s 58us/step - loss: 0.0199 - acc: 0.9976\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0162 - acc: 0.9979\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0204 - acc: 0.9977\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0201 - acc: 0.9977\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0205 - acc: 0.9978\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0186 - acc: 0.9980\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0233 - acc: 0.9976\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0171 - acc: 0.9980\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0180 - acc: 0.9981\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0170 - acc: 0.9981\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0201 - acc: 0.9980\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0180 - acc: 0.9982\n",
      "56862/56862 [==============================] - 3s 56us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_126 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 35s 68us/step - loss: 0.0520 - acc: 0.9879 1s - loss: \n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0411 - acc: 0.9933\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0317 - acc: 0.9948\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0310 - acc: 0.9955\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0276 - acc: 0.9959\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0228 - acc: 0.9965\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0219 - acc: 0.9968\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 30s 60us/step - loss: 0.0206 - acc: 0.9971\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0191 - acc: 0.9973\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0185 - acc: 0.9976\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0237 - acc: 0.9972\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0246 - acc: 0.9972\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0210 - acc: 0.9975\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0208 - acc: 0.9975\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0200 - acc: 0.9978\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0199 - acc: 0.9977\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0165 - acc: 0.9980\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0160 - acc: 0.9981\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0151 - acc: 0.9982\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0146 - acc: 0.9982\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0168 - acc: 0.9981\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0146 - acc: 0.9983\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0200 - acc: 0.9979\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0156 - acc: 0.9981\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0140 - acc: 0.9983\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0172 - acc: 0.9981\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0131 - acc: 0.9986\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0172 - acc: 0.9982\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0145 - acc: 0.9983\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0214 - acc: 0.9979\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0178 - acc: 0.9982\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0184 - acc: 0.9982\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0141 - acc: 0.9985\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0143 - acc: 0.9985\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0203 - acc: 0.9981\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0153 - acc: 0.9984\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0136 - acc: 0.9985\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 30s 60us/step - loss: 0.0146 - acc: 0.9985\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0183 - acc: 0.9983\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0140 - acc: 0.9987\n",
      "56862/56862 [==============================] - 3s 52us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_128 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 33s 64us/step - loss: 0.0598 - acc: 0.9870\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0440 - acc: 0.9926\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0421 - acc: 0.9940\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0335 - acc: 0.9948\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0230 - acc: 0.9964\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0260 - acc: 0.9964\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0249 - acc: 0.9968\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0229 - acc: 0.9968\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0214 - acc: 0.9971\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0233 - acc: 0.9971\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0251 - acc: 0.9970\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0196 - acc: 0.9975\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 30s 60us/step - loss: 0.0215 - acc: 0.9974\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0226 - acc: 0.9975\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0197 - acc: 0.9976\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0156 - acc: 0.9979\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0169 - acc: 0.9980\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0237 - acc: 0.9975\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0206 - acc: 0.9977\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0177 - acc: 0.9979\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0191 - acc: 0.9980\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0197 - acc: 0.9979\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0241 - acc: 0.9976\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0190 - acc: 0.9979\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0180 - acc: 0.9980\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0191 - acc: 0.9979\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0163 - acc: 0.9982\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0207 - acc: 0.9979\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0151 - acc: 0.9983\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0174 - acc: 0.9983\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0223 - acc: 0.9979\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0156 - acc: 0.9983\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0170 - acc: 0.9983\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0174 - acc: 0.9982\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 31s 62us/step - loss: 0.0185 - acc: 0.9982\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 35s 69us/step - loss: 0.0186 - acc: 0.9982\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0241 - acc: 0.9978\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0201 - acc: 0.9982\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 33s 64us/step - loss: 0.0187 - acc: 0.9983\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0216 - acc: 0.9981\n",
      "56862/56862 [==============================] - 3s 58us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_130 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 35s 68us/step - loss: 0.0554 - acc: 0.9879\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0433 - acc: 0.9930\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0401 - acc: 0.9940\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0346 - acc: 0.9948\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0296 - acc: 0.9957\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0265 - acc: 0.9961\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0261 - acc: 0.9962\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0330 - acc: 0.9958\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0291 - acc: 0.9963\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0249 - acc: 0.9967\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0257 - acc: 0.9966\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0270 - acc: 0.9965\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0274 - acc: 0.9967\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0267 - acc: 0.9968\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 33s 64us/step - loss: 0.0217 - acc: 0.9971\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0268 - acc: 0.9968\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0293 - acc: 0.9966\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0262 - acc: 0.9969\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0355 - acc: 0.9965\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0267 - acc: 0.9968\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0213 - acc: 0.9973\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 34s 66us/step - loss: 0.0302 - acc: 0.9967\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0232 - acc: 0.9972\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0309 - acc: 0.9967\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 30s 60us/step - loss: 0.0248 - acc: 0.9973\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0193 - acc: 0.9975\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0233 - acc: 0.9973\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0219 - acc: 0.9975\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0207 - acc: 0.9975\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 30s 60us/step - loss: 0.0218 - acc: 0.9976\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0197 - acc: 0.9977\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0206 - acc: 0.9976\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0239 - acc: 0.9976\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 33s 64us/step - loss: 0.0246 - acc: 0.9975\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 30s 60us/step - loss: 0.0202 - acc: 0.9978\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0220 - acc: 0.9976\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0281 - acc: 0.9973\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0191 - acc: 0.9979\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0245 - acc: 0.9976\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0241 - acc: 0.9976\n",
      "56862/56862 [==============================] - 4s 63us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_132 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 35s 69us/step - loss: 0.0520 - acc: 0.9883\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0353 - acc: 0.9939\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0275 - acc: 0.9953\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0356 - acc: 0.9950\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0283 - acc: 0.9960\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0268 - acc: 0.9961\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0227 - acc: 0.9965\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 27s 52us/step - loss: 0.0254 - acc: 0.9964\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0250 - acc: 0.9966 0s - loss: 0\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 26s 52us/step - loss: 0.0245 - acc: 0.9967\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0247 - acc: 0.9968\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0227 - acc: 0.9969\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 26s 50us/step - loss: 0.0224 - acc: 0.9970 0s - loss: 0.0223 - acc: 0.997 - ETA: 0s - loss: 0.0223 - acc: 0.9\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 26s 50us/step - loss: 0.0237 - acc: 0.9969 0s - loss: 0.0\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 26s 52us/step - loss: 0.0301 - acc: 0.9965\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 26s 50us/step - loss: 0.0256 - acc: 0.9970\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0233 - acc: 0.9970\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0221 - acc: 0.9972 \n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0213 - acc: 0.9975\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0264 - acc: 0.9972\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0228 - acc: 0.9973\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 26s 52us/step - loss: 0.0244 - acc: 0.9972\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0226 - acc: 0.9974\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0195 - acc: 0.9977\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0189 - acc: 0.9978\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0217 - acc: 0.9975\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 26s 50us/step - loss: 0.0197 - acc: 0.9977\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 26s 50us/step - loss: 0.0200 - acc: 0.9977\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0228 - acc: 0.9975\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0204 - acc: 0.9978\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 27s 54us/step - loss: 0.0191 - acc: 0.9979\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0219 - acc: 0.9977\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 26s 51us/step - loss: 0.0241 - acc: 0.9976\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 27s 53us/step - loss: 0.0199 - acc: 0.9978\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0206 - acc: 0.9979\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0223 - acc: 0.9977\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0304 - acc: 0.9972\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0186 - acc: 0.9980\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0228 - acc: 0.9977\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0175 - acc: 0.9981\n",
      "56862/56862 [==============================] - 3s 52us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_134 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 34s 66us/step - loss: 0.0582 - acc: 0.9869\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0356 - acc: 0.9939\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0315 - acc: 0.9949\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0262 - acc: 0.9957\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0285 - acc: 0.9958\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0288 - acc: 0.9960\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0273 - acc: 0.9964\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 27s 52us/step - loss: 0.0231 - acc: 0.9969\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 26s 52us/step - loss: 0.0251 - acc: 0.9968\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 26s 51us/step - loss: 0.0226 - acc: 0.9970\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 27s 52us/step - loss: 0.0221 - acc: 0.9972\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 26s 52us/step - loss: 0.0264 - acc: 0.9969\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0220 - acc: 0.9972\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0208 - acc: 0.9974\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0170 - acc: 0.9976\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0172 - acc: 0.9978\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0203 - acc: 0.9977\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0199 - acc: 0.9977\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0204 - acc: 0.9977\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0188 - acc: 0.9978\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0200 - acc: 0.9977\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0165 - acc: 0.9980\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0167 - acc: 0.9980 0s - loss: 0.0167 - acc: \n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 38s 74us/step - loss: 0.0204 - acc: 0.9979\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0165 - acc: 0.9981\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0141 - acc: 0.9983\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 27s 53us/step - loss: 0.0144 - acc: 0.9984\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 27s 52us/step - loss: 0.0135 - acc: 0.9985\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 26s 52us/step - loss: 0.0164 - acc: 0.9983\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0167 - acc: 0.9984\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0275 - acc: 0.9976\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0195 - acc: 0.9981\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 34s 66us/step - loss: 0.0163 - acc: 0.9984\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0172 - acc: 0.9983\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0153 - acc: 0.9984\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0167 - acc: 0.9985\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0168 - acc: 0.9985\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0212 - acc: 0.9982\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0400 - acc: 0.9970\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 26s 51us/step - loss: 0.0174 - acc: 0.9985\n",
      "56861/56861 [==============================] - 3s 49us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_136 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0569 - acc: 0.9866 1s - \n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 27s 54us/step - loss: 0.0442 - acc: 0.9924\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 34s 67us/step - loss: 0.0434 - acc: 0.9932\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0371 - acc: 0.9944\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0386 - acc: 0.9943\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0368 - acc: 0.9947\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0307 - acc: 0.9953\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0391 - acc: 0.9949\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0349 - acc: 0.9953\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 37s 72us/step - loss: 0.0286 - acc: 0.9960\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0354 - acc: 0.9955\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0393 - acc: 0.9954\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0407 - acc: 0.9954\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0328 - acc: 0.9959\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0305 - acc: 0.9960\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0301 - acc: 0.9961\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0310 - acc: 0.9961\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0318 - acc: 0.9961\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0412 - acc: 0.9954\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0310 - acc: 0.9961\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0373 - acc: 0.9959\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0232 - acc: 0.9968\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0327 - acc: 0.9963\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0285 - acc: 0.9965\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0230 - acc: 0.9969\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0255 - acc: 0.9968\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0279 - acc: 0.9966\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0271 - acc: 0.9967\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0290 - acc: 0.9966\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0239 - acc: 0.9970\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0259 - acc: 0.9970\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0254 - acc: 0.9970\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0253 - acc: 0.9971\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0257 - acc: 0.9971\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0274 - acc: 0.9970\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0242 - acc: 0.9972\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0266 - acc: 0.9971\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0325 - acc: 0.9968\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0273 - acc: 0.9970\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0230 - acc: 0.9973\n",
      "56861/56861 [==============================] - 3s 57us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_138 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0502 - acc: 0.9890\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0377 - acc: 0.9936\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0260 - acc: 0.9957\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0267 - acc: 0.9961\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0290 - acc: 0.9962\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0238 - acc: 0.9969\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0191 - acc: 0.9974\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0201 - acc: 0.9975\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0200 - acc: 0.9974\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0198 - acc: 0.9975\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0169 - acc: 0.9978\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0184 - acc: 0.9977\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0157 - acc: 0.9979\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0172 - acc: 0.9979\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0152 - acc: 0.9981\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0182 - acc: 0.9980\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0162 - acc: 0.9981\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0157 - acc: 0.9982\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0161 - acc: 0.9982\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0165 - acc: 0.9982\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0149 - acc: 0.9983\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0139 - acc: 0.9983\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0144 - acc: 0.9984\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0163 - acc: 0.9982\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0163 - acc: 0.9983\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0144 - acc: 0.9983\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0155 - acc: 0.9983\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0131 - acc: 0.9985\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0134 - acc: 0.9985\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0187 - acc: 0.9981\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0132 - acc: 0.9985\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0162 - acc: 0.9983\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0135 - acc: 0.9985\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0158 - acc: 0.9984\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0170 - acc: 0.9983\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0132 - acc: 0.9985\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0143 - acc: 0.9985\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0130 - acc: 0.9985\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0119 - acc: 0.9987\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0138 - acc: 0.9985\n",
      "56861/56861 [==============================] - 3s 55us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_140 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 34s 67us/step - loss: 0.0591 - acc: 0.9865\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0387 - acc: 0.9934\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0375 - acc: 0.9944\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0403 - acc: 0.9944\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 31s 62us/step - loss: 0.0360 - acc: 0.9950\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0401 - acc: 0.9950\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0342 - acc: 0.9955\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0347 - acc: 0.9957\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0349 - acc: 0.9957\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 31s 62us/step - loss: 0.0267 - acc: 0.9964\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0288 - acc: 0.9965\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0308 - acc: 0.9963\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0286 - acc: 0.9963\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0278 - acc: 0.9966\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0333 - acc: 0.9963\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0267 - acc: 0.9968\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0235 - acc: 0.9971\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0243 - acc: 0.9971\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0238 - acc: 0.9972\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0311 - acc: 0.9968\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0257 - acc: 0.9971\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0243 - acc: 0.9973\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0307 - acc: 0.9969\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0232 - acc: 0.9974\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0253 - acc: 0.9974\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0276 - acc: 0.9973\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0334 - acc: 0.9970\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0360 - acc: 0.9966\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0283 - acc: 0.9972\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0281 - acc: 0.9973\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0310 - acc: 0.9970\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0311 - acc: 0.9971\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0272 - acc: 0.9973 0s - loss: 0.0271 - acc:\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0293 - acc: 0.9973\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0254 - acc: 0.9976\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0208 - acc: 0.9981\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0282 - acc: 0.9976 0s - loss: 0.0282 - acc\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0248 - acc: 0.9978\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0284 - acc: 0.9976\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0226 - acc: 0.9980\n",
      "56861/56861 [==============================] - 3s 56us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_142 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0575 - acc: 0.9879\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0388 - acc: 0.9932\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0333 - acc: 0.9947\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0378 - acc: 0.9948\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0297 - acc: 0.9955\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0254 - acc: 0.9963\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0233 - acc: 0.9966\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0242 - acc: 0.9966\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0225 - acc: 0.9968\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0258 - acc: 0.9967\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0241 - acc: 0.9971 1s \n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0234 - acc: 0.9969\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0243 - acc: 0.9969\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0232 - acc: 0.9970\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0214 - acc: 0.9973\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0206 - acc: 0.9974\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0187 - acc: 0.9976\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0195 - acc: 0.9978\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0209 - acc: 0.9977\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0265 - acc: 0.9971\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0273 - acc: 0.9972\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0234 - acc: 0.9974 3s - loss: 0.0238 - acc: 0.997 - ETA: 3s \n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0185 - acc: 0.9979\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0195 - acc: 0.9979\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0170 - acc: 0.9981\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0166 - acc: 0.9981 2s - loss: 0.0169 - acc: 0\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0184 - acc: 0.9980\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0167 - acc: 0.9981 \n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0183 - acc: 0.9981\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0189 - acc: 0.9981\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0174 - acc: 0.9981\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0159 - acc: 0.9982\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0209 - acc: 0.9980\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0172 - acc: 0.9982\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0171 - acc: 0.9983\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0214 - acc: 0.9980\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0195 - acc: 0.9981\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0202 - acc: 0.9980\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0159 - acc: 0.9983\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0191 - acc: 0.9981\n",
      "56861/56861 [==============================] - 3s 56us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_144 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 35s 69us/step - loss: 0.0464 - acc: 0.9892\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 34s 67us/step - loss: 0.0324 - acc: 0.9944\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 33s 64us/step - loss: 0.0281 - acc: 0.9955\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0311 - acc: 0.9957\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0203 - acc: 0.9968\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0217 - acc: 0.9970\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0208 - acc: 0.9971\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0236 - acc: 0.9971\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0229 - acc: 0.9972\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0182 - acc: 0.9976\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0196 - acc: 0.9975\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0244 - acc: 0.9975\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0179 - acc: 0.9978\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0182 - acc: 0.9979\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0162 - acc: 0.9980\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0151 - acc: 0.9981\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0178 - acc: 0.9979\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0173 - acc: 0.9981\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0189 - acc: 0.9980\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0156 - acc: 0.9982\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0140 - acc: 0.9984\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0162 - acc: 0.9983\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0158 - acc: 0.9983\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0193 - acc: 0.9980\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0225 - acc: 0.9978\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0136 - acc: 0.9985\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0197 - acc: 0.9981\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0176 - acc: 0.9981\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0150 - acc: 0.9984\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0140 - acc: 0.9985\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0168 - acc: 0.9983\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0121 - acc: 0.9987\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0145 - acc: 0.9984\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0137 - acc: 0.9985\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0131 - acc: 0.9986\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0184 - acc: 0.9982\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0147 - acc: 0.9985\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0155 - acc: 0.9985\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0170 - acc: 0.9984\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0179 - acc: 0.9983\n",
      "56862/56862 [==============================] - 3s 56us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_146 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 35s 68us/step - loss: 0.0627 - acc: 0.9864\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0442 - acc: 0.9925\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0405 - acc: 0.9939\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0437 - acc: 0.9941\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0300 - acc: 0.9955\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0321 - acc: 0.9956\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0298 - acc: 0.9960\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0270 - acc: 0.9964\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0315 - acc: 0.9961\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0279 - acc: 0.9964\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0233 - acc: 0.9968\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0260 - acc: 0.9968\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0204 - acc: 0.9972\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0222 - acc: 0.9971\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 33s 64us/step - loss: 0.0262 - acc: 0.9969\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 36s 70us/step - loss: 0.0244 - acc: 0.9972\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 34s 67us/step - loss: 0.0240 - acc: 0.9972\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 35s 68us/step - loss: 0.0198 - acc: 0.9976\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 35s 68us/step - loss: 0.0206 - acc: 0.9975\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 34s 67us/step - loss: 0.0195 - acc: 0.9976\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 35s 68us/step - loss: 0.0240 - acc: 0.9972\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 35s 68us/step - loss: 0.0218 - acc: 0.9974\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 35s 68us/step - loss: 0.0223 - acc: 0.9974\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 34s 67us/step - loss: 0.0220 - acc: 0.9974\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 35s 69us/step - loss: 0.0210 - acc: 0.9976\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 35s 68us/step - loss: 0.0191 - acc: 0.9979\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 35s 68us/step - loss: 0.0219 - acc: 0.9976\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 35s 68us/step - loss: 0.0219 - acc: 0.9977\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 35s 67us/step - loss: 0.0261 - acc: 0.9974\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 35s 68us/step - loss: 0.0210 - acc: 0.9977\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 34s 67us/step - loss: 0.0192 - acc: 0.9979\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 35s 67us/step - loss: 0.0187 - acc: 0.9980\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 34s 66us/step - loss: 0.0205 - acc: 0.9979\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0250 - acc: 0.9975\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0176 - acc: 0.9981\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0224 - acc: 0.9979\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0189 - acc: 0.9980\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0182 - acc: 0.9981\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0194 - acc: 0.9980\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0192 - acc: 0.9980\n",
      "56862/56862 [==============================] - 4s 62us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_148 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 35s 69us/step - loss: 0.0635 - acc: 0.9866\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0465 - acc: 0.9931\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0392 - acc: 0.9942\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0360 - acc: 0.9948\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0302 - acc: 0.9956\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0276 - acc: 0.9960\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0309 - acc: 0.9958\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0277 - acc: 0.9962\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0268 - acc: 0.9964\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0348 - acc: 0.9960\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0243 - acc: 0.9966\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0288 - acc: 0.9965\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0224 - acc: 0.9971\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0196 - acc: 0.9973\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0179 - acc: 0.9976\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0188 - acc: 0.9975\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0183 - acc: 0.9975\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0179 - acc: 0.9976\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0221 - acc: 0.9974\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0186 - acc: 0.9977\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0170 - acc: 0.9979\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0165 - acc: 0.9979\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0197 - acc: 0.9978\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0173 - acc: 0.9980\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0155 - acc: 0.9982\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0209 - acc: 0.9979\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0193 - acc: 0.9979\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0198 - acc: 0.9978\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0189 - acc: 0.9980\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0181 - acc: 0.9980\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0154 - acc: 0.9982\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0163 - acc: 0.9982\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0177 - acc: 0.9981\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0148 - acc: 0.9984\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 30s 60us/step - loss: 0.0144 - acc: 0.9984\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0207 - acc: 0.9980\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0185 - acc: 0.9981 0s - loss: 0.0186\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 30s 60us/step - loss: 0.0149 - acc: 0.9985\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0176 - acc: 0.9983\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0198 - acc: 0.9981\n",
      "56862/56862 [==============================] - 3s 56us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_150 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 33s 65us/step - loss: 0.0560 - acc: 0.9879\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0348 - acc: 0.9942\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0345 - acc: 0.9948\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0293 - acc: 0.9958\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0281 - acc: 0.9960\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0254 - acc: 0.9964\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0253 - acc: 0.9968\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0283 - acc: 0.9966\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0235 - acc: 0.9970\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0381 - acc: 0.9962\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0226 - acc: 0.9973\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0202 - acc: 0.9975 0s - loss: 0.\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0228 - acc: 0.9974\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0216 - acc: 0.9975\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0180 - acc: 0.9978\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0233 - acc: 0.9975\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0243 - acc: 0.9973\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0198 - acc: 0.9978\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0174 - acc: 0.9980\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0174 - acc: 0.9980\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 36s 70us/step - loss: 0.0166 - acc: 0.9982\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0157 - acc: 0.9981\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0164 - acc: 0.9982\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0172 - acc: 0.9982\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0175 - acc: 0.9981\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0197 - acc: 0.9979\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0175 - acc: 0.9980\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0161 - acc: 0.9981\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0215 - acc: 0.9980\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0144 - acc: 0.9985\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0187 - acc: 0.9982 0s - loss: 0.0187 - acc: 0.9\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0176 - acc: 0.9982\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0182 - acc: 0.9982\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0190 - acc: 0.9982\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0204 - acc: 0.9981\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0181 - acc: 0.9982\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0165 - acc: 0.9984\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0222 - acc: 0.9980\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0146 - acc: 0.9985\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0151 - acc: 0.9985\n",
      "56862/56862 [==============================] - 3s 60us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_152 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 34s 66us/step - loss: 0.0538 - acc: 0.9883\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0330 - acc: 0.9941\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0320 - acc: 0.9949\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0331 - acc: 0.9953\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0331 - acc: 0.9956\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0345 - acc: 0.9957\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0258 - acc: 0.9963\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0209 - acc: 0.9970\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0229 - acc: 0.9968\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0217 - acc: 0.9970\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0206 - acc: 0.9971\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0209 - acc: 0.9972\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0242 - acc: 0.9971\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0214 - acc: 0.9973\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0192 - acc: 0.9975\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0258 - acc: 0.9971\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0257 - acc: 0.9972\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0222 - acc: 0.9975\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0184 - acc: 0.9979\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0166 - acc: 0.9979\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0182 - acc: 0.9980\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0192 - acc: 0.9979\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0167 - acc: 0.9981\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0166 - acc: 0.9981\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0187 - acc: 0.9980\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0179 - acc: 0.9980\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0215 - acc: 0.9978\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0189 - acc: 0.9979\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0192 - acc: 0.9979 1s -\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0195 - acc: 0.9978\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0196 - acc: 0.9979\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0189 - acc: 0.9980\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0157 - acc: 0.9983 0s - loss: 0.0\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0159 - acc: 0.9982\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0167 - acc: 0.9982\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0184 - acc: 0.9981\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0163 - acc: 0.9982\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0164 - acc: 0.9982\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0171 - acc: 0.9983\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0156 - acc: 0.9983\n",
      "56862/56862 [==============================] - 3s 58us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_154 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 35s 69us/step - loss: 0.0551 - acc: 0.9867\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0407 - acc: 0.9929\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0355 - acc: 0.9943\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0307 - acc: 0.9952\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0300 - acc: 0.9956\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0316 - acc: 0.9958\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0274 - acc: 0.9962\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0211 - acc: 0.9970\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0240 - acc: 0.9968\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0222 - acc: 0.9970\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0216 - acc: 0.9971\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0210 - acc: 0.9972\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0205 - acc: 0.9973\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0208 - acc: 0.9973\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0204 - acc: 0.9974\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0239 - acc: 0.9973\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0204 - acc: 0.9975\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0179 - acc: 0.9977\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0222 - acc: 0.9974\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0247 - acc: 0.9973\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0180 - acc: 0.9979\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0220 - acc: 0.9976\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0233 - acc: 0.9976\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0186 - acc: 0.9977\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0220 - acc: 0.9975\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0186 - acc: 0.9978\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0189 - acc: 0.9978\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0231 - acc: 0.9976\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0205 - acc: 0.9979\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0212 - acc: 0.9978\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0192 - acc: 0.9978\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0178 - acc: 0.9980 1s - loss: 0.018 - ETA: 0s - loss: 0.0\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0198 - acc: 0.9980\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0185 - acc: 0.9981\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0183 - acc: 0.9980\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0213 - acc: 0.9979\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0164 - acc: 0.9982 0s - loss: 0.0164 - a\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0188 - acc: 0.9981\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0187 - acc: 0.9980\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0165 - acc: 0.9982\n",
      "56861/56861 [==============================] - 3s 58us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_156 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 35s 69us/step - loss: 0.0595 - acc: 0.9868\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0355 - acc: 0.9934\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0326 - acc: 0.9943\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0318 - acc: 0.9950\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0308 - acc: 0.9954\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0299 - acc: 0.9956 2s - loss: \n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0290 - acc: 0.9958\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0270 - acc: 0.9961\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0244 - acc: 0.9965\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0307 - acc: 0.9962\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0220 - acc: 0.9970\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0233 - acc: 0.9969\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0229 - acc: 0.9969\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0219 - acc: 0.9971\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 31s 62us/step - loss: 0.0213 - acc: 0.9973\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0227 - acc: 0.9972\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0192 - acc: 0.9974\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0197 - acc: 0.9974\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0193 - acc: 0.9976\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0200 - acc: 0.9975\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0231 - acc: 0.9974\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0182 - acc: 0.9978 0s - loss: 0.0180 - acc: 0.9\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0187 - acc: 0.9978\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0193 - acc: 0.9977\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0182 - acc: 0.9978\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0210 - acc: 0.9976\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0196 - acc: 0.9977\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0215 - acc: 0.9976\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0174 - acc: 0.9979\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0151 - acc: 0.9982\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0182 - acc: 0.9979\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0176 - acc: 0.9979\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0163 - acc: 0.9980\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0202 - acc: 0.9978 1s -\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0203 - acc: 0.9978\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0150 - acc: 0.9982\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0205 - acc: 0.9979\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0171 - acc: 0.9981\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0181 - acc: 0.9981\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0169 - acc: 0.9981\n",
      "56861/56861 [==============================] - 3s 58us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_158 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 34s 66us/step - loss: 0.0560 - acc: 0.9872\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0413 - acc: 0.9929\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0371 - acc: 0.9943\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0317 - acc: 0.9952\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0371 - acc: 0.9951\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0267 - acc: 0.9961\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0276 - acc: 0.9963\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0308 - acc: 0.9961\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0250 - acc: 0.9968\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0278 - acc: 0.9967\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0231 - acc: 0.9970\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0230 - acc: 0.9970\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0214 - acc: 0.9971\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0217 - acc: 0.9973\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0201 - acc: 0.9974\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0208 - acc: 0.9974\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0255 - acc: 0.9972 0s - loss: 0.0257 - acc\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0211 - acc: 0.9974\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0216 - acc: 0.9975\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0197 - acc: 0.9975\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0224 - acc: 0.9974\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0204 - acc: 0.9976\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0207 - acc: 0.9975\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0308 - acc: 0.9969\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - ETA: 0s - loss: 0.0175 - acc: 0.997 - 31s 60us/step - loss: 0.0175 - acc: 0.9978\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0219 - acc: 0.9976\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0233 - acc: 0.9975\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0224 - acc: 0.9975\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0191 - acc: 0.9978\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0175 - acc: 0.9979\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0181 - acc: 0.9980\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0202 - acc: 0.9979\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0203 - acc: 0.9979\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0215 - acc: 0.9979\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0193 - acc: 0.9979\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0193 - acc: 0.9979\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0189 - acc: 0.9981\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0179 - acc: 0.9980\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0228 - acc: 0.9978\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0224 - acc: 0.9978\n",
      "56861/56861 [==============================] - 3s 61us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_160 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 35s 68us/step - loss: 0.0577 - acc: 0.9878\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0317 - acc: 0.9942\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0312 - acc: 0.9950\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0287 - acc: 0.9958\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0259 - acc: 0.9963\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0285 - acc: 0.9961\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0247 - acc: 0.9965\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0235 - acc: 0.9968\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0215 - acc: 0.9970\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0264 - acc: 0.9968\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0222 - acc: 0.9971\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0298 - acc: 0.9967\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0223 - acc: 0.9974\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0221 - acc: 0.9974\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0239 - acc: 0.9972\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0163 - acc: 0.9978\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0236 - acc: 0.9974\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0206 - acc: 0.9976\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 35s 67us/step - loss: 0.0185 - acc: 0.9977\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 34s 67us/step - loss: 0.0217 - acc: 0.9975\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 34s 67us/step - loss: 0.0185 - acc: 0.9978\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0192 - acc: 0.9979\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0180 - acc: 0.9979\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0170 - acc: 0.9980\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0163 - acc: 0.9980\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0144 - acc: 0.9983\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0223 - acc: 0.9978\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0186 - acc: 0.9981\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0166 - acc: 0.9982\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0148 - acc: 0.9983 0s - loss: 0.01\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 34s 66us/step - loss: 0.0174 - acc: 0.9982\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0147 - acc: 0.9985\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0217 - acc: 0.9979\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0175 - acc: 0.9982\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0227 - acc: 0.9980\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0193 - acc: 0.9981\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0277 - acc: 0.9977\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0223 - acc: 0.9980\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0233 - acc: 0.9979\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0228 - acc: 0.9979\n",
      "56861/56861 [==============================] - 3s 55us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_162 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0713 - acc: 0.9855\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0492 - acc: 0.9915\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0430 - acc: 0.9929\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0339 - acc: 0.9944\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0307 - acc: 0.9952\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0307 - acc: 0.9956 0s - loss: 0.0307 - acc: 0.99\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0309 - acc: 0.9958\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0292 - acc: 0.9961\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0288 - acc: 0.9963\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0297 - acc: 0.9963\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0290 - acc: 0.9966\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 28s 56us/step - loss: 0.0232 - acc: 0.9971\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 29s 57us/step - loss: 0.0243 - acc: 0.9970\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 28s 56us/step - loss: 0.0291 - acc: 0.9968\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0257 - acc: 0.9970\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0233 - acc: 0.9972\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0273 - acc: 0.9970\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 28s 56us/step - loss: 0.0249 - acc: 0.9972\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 28s 56us/step - loss: 0.0225 - acc: 0.9974\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0253 - acc: 0.9972\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0233 - acc: 0.9974 0s - loss: 0.023\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0237 - acc: 0.9975\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 28s 55us/step - loss: 0.0210 - acc: 0.9977\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0198 - acc: 0.9976\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 28s 56us/step - loss: 0.0221 - acc: 0.9976\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0275 - acc: 0.9973\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0204 - acc: 0.9978\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0229 - acc: 0.9976\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0252 - acc: 0.9975 1s - \n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0262 - acc: 0.9975\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 28s 56us/step - loss: 0.0234 - acc: 0.9977 0s - loss: 0.0235\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0322 - acc: 0.9971\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0251 - acc: 0.9976\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0208 - acc: 0.9979\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0265 - acc: 0.9975\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0263 - acc: 0.9975\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 28s 56us/step - loss: 0.0214 - acc: 0.9980\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0213 - acc: 0.9978\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 29s 56us/step - loss: 0.0227 - acc: 0.9979\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 28s 55us/step - loss: 0.0218 - acc: 0.9979 1s \n",
      "56861/56861 [==============================] - 3s 59us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_164 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 33s 65us/step - loss: 0.0550 - acc: 0.9884\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0388 - acc: 0.9935\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0360 - acc: 0.9946\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0341 - acc: 0.9952\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0291 - acc: 0.9959\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0257 - acc: 0.9963\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0261 - acc: 0.9964 0s - loss: 0.0259 - acc\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0250 - acc: 0.9965\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0267 - acc: 0.9965\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0295 - acc: 0.9963\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0282 - acc: 0.9966\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0264 - acc: 0.9966\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0244 - acc: 0.9969\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0261 - acc: 0.9969\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0230 - acc: 0.9971\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0284 - acc: 0.9968\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0230 - acc: 0.9973\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0183 - acc: 0.9976\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0203 - acc: 0.9976\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0225 - acc: 0.9975\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0203 - acc: 0.9975\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0187 - acc: 0.9978\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0191 - acc: 0.9978\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0230 - acc: 0.9976\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0204 - acc: 0.9978\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0197 - acc: 0.9978 1s - loss:\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0282 - acc: 0.9972\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0183 - acc: 0.9979\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0162 - acc: 0.9981\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0188 - acc: 0.9979\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0151 - acc: 0.9982\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0165 - acc: 0.9981\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0167 - acc: 0.9982\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0182 - acc: 0.9982\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 29s 56us/step - loss: 0.0207 - acc: 0.9979 1s\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0174 - acc: 0.9982\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0154 - acc: 0.9983\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0132 - acc: 0.9985\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0150 - acc: 0.9985 0s - loss: 0.0149 - acc: 0.99\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0161 - acc: 0.9983\n",
      "56862/56862 [==============================] - 3s 60us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_166 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0506 - acc: 0.9885\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0409 - acc: 0.9936\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0410 - acc: 0.9944\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0364 - acc: 0.9950\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0355 - acc: 0.9954 0s - loss: 0.0357 - acc\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0283 - acc: 0.9962\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0253 - acc: 0.9966 1s - los\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0292 - acc: 0.9963\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0269 - acc: 0.9966\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0256 - acc: 0.9968\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0210 - acc: 0.9973\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0280 - acc: 0.9967\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0271 - acc: 0.9969\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0256 - acc: 0.9969\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0246 - acc: 0.9972\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 29s 58us/step - loss: 0.0229 - acc: 0.9974\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0215 - acc: 0.9975\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0276 - acc: 0.9972\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0240 - acc: 0.9974\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0220 - acc: 0.9975\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0244 - acc: 0.9974\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0244 - acc: 0.9974\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0198 - acc: 0.9977\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0314 - acc: 0.9971 0s - loss: 0.0312 - acc: 0.99\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0266 - acc: 0.9973\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0216 - acc: 0.9978\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0246 - acc: 0.9975\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0235 - acc: 0.9976 1s - loss:  - ETA: 0s - loss: 0.0235 - acc: 0.997\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0211 - acc: 0.9978\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0210 - acc: 0.9979\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0191 - acc: 0.9981\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0205 - acc: 0.9979\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0195 - acc: 0.9980\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0216 - acc: 0.9980\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0197 - acc: 0.9980\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0175 - acc: 0.9982\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0217 - acc: 0.9979\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0221 - acc: 0.9978\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0224 - acc: 0.9977\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 29s 58us/step - loss: 0.0228 - acc: 0.9978\n",
      "56862/56862 [==============================] - 3s 59us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_168 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 34s 67us/step - loss: 0.0591 - acc: 0.9873\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0471 - acc: 0.9923\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0362 - acc: 0.9941\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0323 - acc: 0.9949\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0331 - acc: 0.9951\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0283 - acc: 0.9956\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0261 - acc: 0.9959\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0299 - acc: 0.9959\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0267 - acc: 0.9962 0s - loss: 0\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0325 - acc: 0.9961\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0248 - acc: 0.9968 0s - loss: 0.0248 - acc: \n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0243 - acc: 0.9968\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0212 - acc: 0.9971\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0219 - acc: 0.9972\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0254 - acc: 0.9968\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 29s 58us/step - loss: 0.0261 - acc: 0.9969\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0333 - acc: 0.9965\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 29s 58us/step - loss: 0.0246 - acc: 0.9972\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 29s 58us/step - loss: 0.0236 - acc: 0.9971\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 33s 64us/step - loss: 0.0224 - acc: 0.9973\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0209 - acc: 0.9975\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0263 - acc: 0.9972\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0211 - acc: 0.9975\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 33s 64us/step - loss: 0.0217 - acc: 0.9973\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 33s 64us/step - loss: 0.0264 - acc: 0.9971\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0230 - acc: 0.9974\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0221 - acc: 0.9975\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0269 - acc: 0.9972\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0237 - acc: 0.9973\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 33s 64us/step - loss: 0.0199 - acc: 0.9977\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0241 - acc: 0.9975\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0215 - acc: 0.9975\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0213 - acc: 0.9976\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0190 - acc: 0.9978\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0234 - acc: 0.9976\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 33s 64us/step - loss: 0.0212 - acc: 0.9978\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 33s 64us/step - loss: 0.0286 - acc: 0.9973\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0192 - acc: 0.9980\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0212 - acc: 0.9979\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0248 - acc: 0.9977\n",
      "56862/56862 [==============================] - 4s 63us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_170 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 33s 65us/step - loss: 0.0556 - acc: 0.9870\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0401 - acc: 0.9930\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0415 - acc: 0.9938\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0379 - acc: 0.9943\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0339 - acc: 0.9949\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0349 - acc: 0.9952\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0378 - acc: 0.9949\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0322 - acc: 0.9956\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0309 - acc: 0.9958\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0364 - acc: 0.9957\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0321 - acc: 0.9961\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0305 - acc: 0.9962 0s - loss: 0.0306 - a\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0343 - acc: 0.9962\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 32s 63us/step - loss: 0.0361 - acc: 0.9961\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 31s 62us/step - loss: 0.0317 - acc: 0.9963\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0325 - acc: 0.9961\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0293 - acc: 0.9965\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0295 - acc: 0.9965\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0290 - acc: 0.9966\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0271 - acc: 0.9968\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0226 - acc: 0.9972\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0367 - acc: 0.9963\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0342 - acc: 0.9964\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 29s 58us/step - loss: 0.0270 - acc: 0.9970\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0232 - acc: 0.9972 0s - loss: 0.0233 - acc: \n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0265 - acc: 0.9970\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0247 - acc: 0.9973\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0274 - acc: 0.9971\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0302 - acc: 0.9968\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0229 - acc: 0.9973\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0296 - acc: 0.9969\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0247 - acc: 0.9972\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0263 - acc: 0.9972\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0225 - acc: 0.9974\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0267 - acc: 0.9972\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0249 - acc: 0.9973\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0258 - acc: 0.9972\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0214 - acc: 0.9975 1s - loss: 0.0213 - acc: 0.997 - ETA: 0s - los\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0241 - acc: 0.9974 0s - loss: 0.0233 - \n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0225 - acc: 0.9975 0s - loss: 0.0222 - acc\n",
      "56862/56862 [==============================] - 4s 62us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_172 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511753/511753 [==============================] - 33s 64us/step - loss: 0.0524 - acc: 0.9884\n",
      "Epoch 2/40\n",
      "511753/511753 [==============================] - 29s 58us/step - loss: 0.0393 - acc: 0.9934\n",
      "Epoch 3/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0384 - acc: 0.9942\n",
      "Epoch 4/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0310 - acc: 0.9952\n",
      "Epoch 5/40\n",
      "511753/511753 [==============================] - 29s 58us/step - loss: 0.0303 - acc: 0.9955\n",
      "Epoch 6/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0308 - acc: 0.9957\n",
      "Epoch 7/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0316 - acc: 0.9960\n",
      "Epoch 8/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0304 - acc: 0.9962\n",
      "Epoch 9/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0284 - acc: 0.9964\n",
      "Epoch 10/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0260 - acc: 0.9966\n",
      "Epoch 11/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0288 - acc: 0.9964\n",
      "Epoch 12/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0262 - acc: 0.9965\n",
      "Epoch 13/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0265 - acc: 0.9965\n",
      "Epoch 14/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0240 - acc: 0.9968\n",
      "Epoch 15/40\n",
      "511753/511753 [==============================] - 29s 58us/step - loss: 0.0239 - acc: 0.9971\n",
      "Epoch 16/40\n",
      "511753/511753 [==============================] - 29s 58us/step - loss: 0.0214 - acc: 0.9973\n",
      "Epoch 17/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0203 - acc: 0.9973\n",
      "Epoch 18/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0210 - acc: 0.9976\n",
      "Epoch 19/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0262 - acc: 0.9973\n",
      "Epoch 20/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0231 - acc: 0.9973\n",
      "Epoch 21/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0244 - acc: 0.9974\n",
      "Epoch 22/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0188 - acc: 0.9979\n",
      "Epoch 23/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0204 - acc: 0.9978\n",
      "Epoch 24/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0195 - acc: 0.9979\n",
      "Epoch 25/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0199 - acc: 0.9978 0s - loss: 0.0199 - acc: 0.99\n",
      "Epoch 26/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0211 - acc: 0.9977\n",
      "Epoch 27/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0172 - acc: 0.9981\n",
      "Epoch 28/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0201 - acc: 0.9979\n",
      "Epoch 29/40\n",
      "511753/511753 [==============================] - 32s 62us/step - loss: 0.0182 - acc: 0.9981\n",
      "Epoch 30/40\n",
      "511753/511753 [==============================] - 31s 60us/step - loss: 0.0251 - acc: 0.9976\n",
      "Epoch 31/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0211 - acc: 0.9979\n",
      "Epoch 32/40\n",
      "511753/511753 [==============================] - 31s 61us/step - loss: 0.0200 - acc: 0.9980\n",
      "Epoch 33/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0182 - acc: 0.9981\n",
      "Epoch 34/40\n",
      "511753/511753 [==============================] - 30s 59us/step - loss: 0.0174 - acc: 0.9981\n",
      "Epoch 35/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0203 - acc: 0.9979\n",
      "Epoch 36/40\n",
      "511753/511753 [==============================] - 29s 58us/step - loss: 0.0249 - acc: 0.9976\n",
      "Epoch 37/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0184 - acc: 0.9981\n",
      "Epoch 38/40\n",
      "511753/511753 [==============================] - 29s 57us/step - loss: 0.0179 - acc: 0.9981\n",
      "Epoch 39/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0163 - acc: 0.9983 0s - loss: 0.0163 - acc\n",
      "Epoch 40/40\n",
      "511753/511753 [==============================] - 30s 58us/step - loss: 0.0170 - acc: 0.9982\n",
      "56862/56862 [==============================] - 3s 60us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_174 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 34s 66us/step - loss: 0.0622 - acc: 0.9861\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0414 - acc: 0.9927\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0371 - acc: 0.9941\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0336 - acc: 0.9949\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0299 - acc: 0.9955\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0317 - acc: 0.9956\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0295 - acc: 0.9960\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0275 - acc: 0.9963\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0255 - acc: 0.9965\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 34s 67us/step - loss: 0.0241 - acc: 0.9967\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0271 - acc: 0.9966\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0263 - acc: 0.9967\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0223 - acc: 0.9971\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0231 - acc: 0.9970\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0194 - acc: 0.9973\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0266 - acc: 0.9969\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0190 - acc: 0.9975 1s - loss: 0.0193 - acc: - ETA: 0s - loss: 0.0192 - acc: 0.997 - ETA: 0s - loss: 0.0\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0201 - acc: 0.9974\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0211 - acc: 0.9974\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0182 - acc: 0.9977\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0169 - acc: 0.9978\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0197 - acc: 0.9977\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0191 - acc: 0.9977\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0194 - acc: 0.9978\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0188 - acc: 0.9978\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0289 - acc: 0.9972\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0192 - acc: 0.9978\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0297 - acc: 0.9971\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0182 - acc: 0.9979\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0187 - acc: 0.9979 1s - los\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0213 - acc: 0.9978\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0231 - acc: 0.9975\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0239 - acc: 0.9976\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0201 - acc: 0.9978\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0178 - acc: 0.9981\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0261 - acc: 0.9975\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0205 - acc: 0.9979\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0194 - acc: 0.9980 1s - loss: \n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0170 - acc: 0.9981\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0194 - acc: 0.9980 1s - \n",
      "56861/56861 [==============================] - 3s 61us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_176 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0601 - acc: 0.9866\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0453 - acc: 0.9936\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0463 - acc: 0.9947\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0403 - acc: 0.9954\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0407 - acc: 0.9959\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0426 - acc: 0.9957\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0460 - acc: 0.9959\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0580 - acc: 0.9949\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0564 - acc: 0.9950\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0626 - acc: 0.9947\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0667 - acc: 0.9953\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0678 - acc: 0.9950\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0649 - acc: 0.9950\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0710 - acc: 0.9951\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0551 - acc: 0.9953\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0606 - acc: 0.9957\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0631 - acc: 0.9955\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0584 - acc: 0.9950\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0643 - acc: 0.9945\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0540 - acc: 0.9957\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0499 - acc: 0.9964\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0441 - acc: 0.9963\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0470 - acc: 0.9965\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0479 - acc: 0.9965\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0535 - acc: 0.9963\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0571 - acc: 0.9959\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0547 - acc: 0.9965\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0560 - acc: 0.9962\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0584 - acc: 0.9947\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0458 - acc: 0.9968\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.1163 - acc: 0.9926\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0616 - acc: 0.9960\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0446 - acc: 0.9968\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0459 - acc: 0.9967\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0586 - acc: 0.9961\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0693 - acc: 0.9943\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0657 - acc: 0.9958\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0510 - acc: 0.9966\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0433 - acc: 0.9970\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0645 - acc: 0.9951\n",
      "56861/56861 [==============================] - 3s 61us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_178 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0551 - acc: 0.9880\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0381 - acc: 0.9936\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0302 - acc: 0.9951 0s - loss: 0.0301 - acc: \n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0278 - acc: 0.9959\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0227 - acc: 0.9965\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0224 - acc: 0.9968\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0268 - acc: 0.9965\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0272 - acc: 0.9967\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0219 - acc: 0.9970\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0206 - acc: 0.9973\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0211 - acc: 0.9973\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0210 - acc: 0.9974 0s - loss: 0.0210 - acc: 0.9\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0195 - acc: 0.9976 2s - loss: 0.0181  - ETA\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0253 - acc: 0.9973\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0205 - acc: 0.9976\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0173 - acc: 0.9979\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0181 - acc: 0.9978\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0167 - acc: 0.9980\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 31s 61us/step - loss: 0.0159 - acc: 0.9981\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0173 - acc: 0.9981\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0179 - acc: 0.9980\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0157 - acc: 0.9983 1s - loss: 0.015 - ETA: 1s - loss:\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0179 - acc: 0.9980\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0183 - acc: 0.9980\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0193 - acc: 0.9980\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0147 - acc: 0.9983\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0170 - acc: 0.9982 0s - loss: 0.01\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0155 - acc: 0.9982\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0137 - acc: 0.9984 \n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0140 - acc: 0.9985\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0206 - acc: 0.9981\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0129 - acc: 0.9985\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0137 - acc: 0.9985\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0136 - acc: 0.9984\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0182 - acc: 0.9981\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0158 - acc: 0.9983\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0177 - acc: 0.9982\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0138 - acc: 0.9985\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 30s 58us/step - loss: 0.0159 - acc: 0.9984\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0147 - acc: 0.9984\n",
      "56861/56861 [==============================] - 3s 61us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_180 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 34s 67us/step - loss: 0.0585 - acc: 0.9871\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0379 - acc: 0.9929\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 35s 67us/step - loss: 0.0306 - acc: 0.9945\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 34s 66us/step - loss: 0.0361 - acc: 0.9947\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0315 - acc: 0.9955\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0376 - acc: 0.9950\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 34s 65us/step - loss: 0.0273 - acc: 0.9961\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0248 - acc: 0.9964\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0239 - acc: 0.9966 0s - loss: 0.023\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0288 - acc: 0.9963\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 34s 67us/step - loss: 0.0211 - acc: 0.9971\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0250 - acc: 0.9968\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0232 - acc: 0.9970\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0263 - acc: 0.9969\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0270 - acc: 0.9969\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0271 - acc: 0.9969\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0258 - acc: 0.9971\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0278 - acc: 0.9970\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0243 - acc: 0.9971\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0217 - acc: 0.9975\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0213 - acc: 0.9975\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0253 - acc: 0.9974\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0226 - acc: 0.9976\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0209 - acc: 0.9977\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0189 - acc: 0.9979\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0174 - acc: 0.9981\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0166 - acc: 0.9982\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0227 - acc: 0.9978 0s - loss: 0.0226 - acc: 0\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0189 - acc: 0.9980\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 33s 65us/step - loss: 0.0200 - acc: 0.9979\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0178 - acc: 0.9981\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 32s 62us/step - loss: 0.0163 - acc: 0.9982\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 34s 66us/step - loss: 0.0174 - acc: 0.9982\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 34s 66us/step - loss: 0.0162 - acc: 0.9982\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 36s 70us/step - loss: 0.0164 - acc: 0.9982\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0219 - acc: 0.9979\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0191 - acc: 0.9981 0s - loss: 0.0191 - acc: 0\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0190 - acc: 0.9981\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0144 - acc: 0.9985\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0180 - acc: 0.9982\n",
      "56861/56861 [==============================] - 4s 65us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_182 (Dense)            (None, 19)                551       \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "511754/511754 [==============================] - 34s 66us/step - loss: 0.0615 - acc: 0.9867\n",
      "Epoch 2/40\n",
      "511754/511754 [==============================] - 30s 59us/step - loss: 0.0437 - acc: 0.9925\n",
      "Epoch 3/40\n",
      "511754/511754 [==============================] - 31s 60us/step - loss: 0.0394 - acc: 0.9939\n",
      "Epoch 4/40\n",
      "511754/511754 [==============================] - 30s 60us/step - loss: 0.0364 - acc: 0.9949\n",
      "Epoch 5/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0386 - acc: 0.9949\n",
      "Epoch 6/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0338 - acc: 0.9955\n",
      "Epoch 7/40\n",
      "511754/511754 [==============================] - 33s 64us/step - loss: 0.0296 - acc: 0.9960\n",
      "Epoch 8/40\n",
      "511754/511754 [==============================] - 32s 63us/step - loss: 0.0268 - acc: 0.9963\n",
      "Epoch 9/40\n",
      "511754/511754 [==============================] - 35s 68us/step - loss: 0.0333 - acc: 0.9959\n",
      "Epoch 10/40\n",
      "511754/511754 [==============================] - 35s 69us/step - loss: 0.0243 - acc: 0.9966\n",
      "Epoch 11/40\n",
      "511754/511754 [==============================] - 37s 72us/step - loss: 0.0272 - acc: 0.9967\n",
      "Epoch 12/40\n",
      "511754/511754 [==============================] - 36s 71us/step - loss: 0.0275 - acc: 0.9965\n",
      "Epoch 13/40\n",
      "511754/511754 [==============================] - 36s 70us/step - loss: 0.0234 - acc: 0.9970\n",
      "Epoch 14/40\n",
      "511754/511754 [==============================] - 35s 69us/step - loss: 0.0215 - acc: 0.9972\n",
      "Epoch 15/40\n",
      "511754/511754 [==============================] - 35s 68us/step - loss: 0.0243 - acc: 0.9970\n",
      "Epoch 16/40\n",
      "511754/511754 [==============================] - 35s 68us/step - loss: 0.0226 - acc: 0.9971\n",
      "Epoch 17/40\n",
      "511754/511754 [==============================] - 35s 68us/step - loss: 0.0183 - acc: 0.9975\n",
      "Epoch 18/40\n",
      "511754/511754 [==============================] - 35s 68us/step - loss: 0.0191 - acc: 0.9975\n",
      "Epoch 19/40\n",
      "511754/511754 [==============================] - 35s 68us/step - loss: 0.0205 - acc: 0.9975\n",
      "Epoch 20/40\n",
      "511754/511754 [==============================] - 35s 68us/step - loss: 0.0195 - acc: 0.9976\n",
      "Epoch 21/40\n",
      "511754/511754 [==============================] - 40s 77us/step - loss: 0.0201 - acc: 0.9976\n",
      "Epoch 22/40\n",
      "511754/511754 [==============================] - 35s 69us/step - loss: 0.0249 - acc: 0.9974\n",
      "Epoch 23/40\n",
      "511754/511754 [==============================] - 36s 70us/step - loss: 0.0192 - acc: 0.9978\n",
      "Epoch 24/40\n",
      "511754/511754 [==============================] - 36s 70us/step - loss: 0.0235 - acc: 0.9975\n",
      "Epoch 25/40\n",
      "511754/511754 [==============================] - 36s 70us/step - loss: 0.0198 - acc: 0.9977\n",
      "Epoch 26/40\n",
      "511754/511754 [==============================] - 36s 70us/step - loss: 0.0197 - acc: 0.9979\n",
      "Epoch 27/40\n",
      "511754/511754 [==============================] - 36s 71us/step - loss: 0.0200 - acc: 0.9978\n",
      "Epoch 28/40\n",
      "511754/511754 [==============================] - 35s 68us/step - loss: 0.0162 - acc: 0.9980\n",
      "Epoch 29/40\n",
      "511754/511754 [==============================] - 35s 68us/step - loss: 0.0202 - acc: 0.9978\n",
      "Epoch 30/40\n",
      "511754/511754 [==============================] - 35s 69us/step - loss: 0.0171 - acc: 0.9980\n",
      "Epoch 31/40\n",
      "511754/511754 [==============================] - 35s 69us/step - loss: 0.0268 - acc: 0.9974\n",
      "Epoch 32/40\n",
      "511754/511754 [==============================] - 35s 69us/step - loss: 0.0186 - acc: 0.9980\n",
      "Epoch 33/40\n",
      "511754/511754 [==============================] - 35s 69us/step - loss: 0.0197 - acc: 0.9979\n",
      "Epoch 34/40\n",
      "511754/511754 [==============================] - 35s 69us/step - loss: 0.0199 - acc: 0.9979- ETA: 0s - loss: 0.0200 - acc: 0.\n",
      "Epoch 35/40\n",
      "511754/511754 [==============================] - 35s 69us/step - loss: 0.0164 - acc: 0.9981\n",
      "Epoch 36/40\n",
      "511754/511754 [==============================] - 36s 70us/step - loss: 0.0184 - acc: 0.9979\n",
      "Epoch 37/40\n",
      "511754/511754 [==============================] - 36s 70us/step - loss: 0.0187 - acc: 0.9979\n",
      "Epoch 38/40\n",
      "511754/511754 [==============================] - 36s 71us/step - loss: 0.0159 - acc: 0.9981\n",
      "Epoch 39/40\n",
      "511754/511754 [==============================] - 36s 71us/step - loss: 0.0186 - acc: 0.9981\n",
      "Epoch 40/40\n",
      "511754/511754 [==============================] - 35s 69us/step - loss: 0.0210 - acc: 0.9979\n",
      "56861/56861 [==============================] - 4s 71us/step\n"
     ]
    }
   ],
   "source": [
    "#generate 30 samples\n",
    "for _ in range(0,3):\n",
    "    seed = _\n",
    "    np.random.seed(seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    for train, test in kfold.split(X, y):\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Dense(19, input_shape=(28,), activation='relu' ))\n",
    "        model.add(keras.layers.Dense(2,  activation='softmax' ))\n",
    "        model.compile(keras.optimizers.Adam(lr=0.04), 'categorical_crossentropy', metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        experiment_history = model.fit(X[train], keras.utils.to_categorical(y[train],num_classes=None) , epochs=40, verbose=1)\n",
    "        #print(\"iteration-{} complete!!!\".format(_))\n",
    "        test_loss, test_acc = model.evaluate(X[test], keras.utils.to_categorical(y[test],num_classes=None))\n",
    "        results_experiment_evaluation_accuracy.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.99732686152439243,\n",
       " 0.99876894938623328,\n",
       " 0.99857549857549854,\n",
       " 0.98243114909781581,\n",
       " 0.99831170201540576,\n",
       " 0.99753785547211626,\n",
       " 0.9975730289653717,\n",
       " 0.99889203496245227,\n",
       " 0.99831167232373685,\n",
       " 0.99794235064455428,\n",
       " 0.9986458443248567,\n",
       " 0.99827652914072662,\n",
       " 0.99852273926348001,\n",
       " 0.99861067145017768,\n",
       " 0.99839963420210331,\n",
       " 0.99845236629675871,\n",
       " 0.99834684581699229,\n",
       " 0.9982237385905981,\n",
       " 0.99803028437769292,\n",
       " 0.99815339160408711,\n",
       " 0.9986458443248567,\n",
       " 0.99855791213815903,\n",
       " 0.99590236009989097,\n",
       " 0.99753789877246668,\n",
       " 0.99857549857549854,\n",
       " 0.99862823376303622,\n",
       " 0.99577918080934213,\n",
       " 0.99882168797594129,\n",
       " 0.99843477955013105,\n",
       " 0.99834684581699229]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_experiment_evaluation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saving results\n",
    "pd.DataFrame(results_control_evaluation_accuracy).to_csv('results_control_evaluation_accuracy.csv', index=False)\n",
    "pd.DataFrame(results_experiment_evaluation_accuracy).to_csv('results_experiment_evaluation_accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "control = pd.DataFrame(results_control_evaluation_accuracy)\n",
    "experiment = pd.DataFrame(results_experiment_evaluation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Control Accuracy: 0    0.998061\n",
      "dtype: float64\n",
      "Mean Experimental Accuracy: 0    0.997619\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "##Basic Stats\n",
    "mean_control_accuracy = control.mean()\n",
    "print(\"Mean Control Accuracy: {}\".format(mean_control_accuracy))\n",
    "\n",
    "mean_experimental_accuracy = experiment.mean()\n",
    "print(\"Mean Experimental Accuracy: {}\".format(mean_experimental_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Control Accuracy Results: 0    0.000996\n",
      "dtype: float64\n",
      "Standard Deviation of Experimental Accuracy Results: 0    0.002962\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "##Checking standard deviation of the results\n",
    "std_control_accuracy = control.std()\n",
    "print(\"Standard Deviation of Control Accuracy Results: {}\".format(std_control_accuracy))\n",
    "\n",
    "std_experimental_accuracy = experiment.std()\n",
    "print(\"Standard Deviation of Experimental Accuracy Results: {}\".format(std_experimental_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Control</th>\n",
       "      <th>Experimental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998136</td>\n",
       "      <td>0.997327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.996958</td>\n",
       "      <td>0.998769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.998575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997890</td>\n",
       "      <td>0.982431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998294</td>\n",
       "      <td>0.998312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Control  Experimental\n",
       "0  0.998136      0.997327\n",
       "1  0.996958      0.998769\n",
       "2  0.998857      0.998575\n",
       "3  0.997890      0.982431\n",
       "4  0.998294      0.998312"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_accuracy= pd.concat([control, experiment], axis=1)\n",
    "results_accuracy.columns = ['Control', 'Experimental']\n",
    "results_accuracy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bab6d586d8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWtePL8IklwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bab6e9cdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To calculate 5 parameter representation of results using boxplots\n",
    "results_accuracy.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bae6220438>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bae622ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#taking away outliers\n",
    "results_accuracy.boxplot(showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null hypothesis accepted, no significant difference between the data-sets\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "s, p = stats.wilcoxon(control[0], experiment[0])\n",
    "\n",
    "if p < 0.05:\n",
    "  print('null hypothesis rejected, significant difference between the data-sets')\n",
    "else:\n",
    "  print('null hypothesis accepted, no significant difference between the data-sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
